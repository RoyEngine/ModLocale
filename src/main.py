#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ModLocale ä¸»å…¥å£

æä¾›Extractã€Extendå’ŒDecompileä¸‰ç§æ¨¡å¼çš„é€‰æ‹©å’Œæ‰§è¡Œï¼Œä»¥åŠæ˜ å°„è§„åˆ™ç®¡ç†å’Œå®Œæ•´å·¥ä½œæµåŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
python main.py [æ¨¡å—åç§°] [å‚æ•°]

æ¨¡å—åˆ—è¡¨ï¼š
- extract: æ‰§è¡ŒExtractæ¨¡å¼ï¼Œç”¨äºæå–å­—ç¬¦ä¸²
- extend: æ‰§è¡ŒExtendæ¨¡å¼ï¼Œç”¨äºæ˜ å°„å­—ç¬¦ä¸²
- decompile: æ‰§è¡ŒDecompileæ¨¡å¼ï¼Œç”¨äºåç¼–è¯‘æˆ–æå–JARæ–‡ä»¶
- localization: æ‰§è¡Œæ˜ å°„è§„åˆ™ç®¡ç†ï¼ˆç”Ÿæˆ/æ›´æ–°/å†²çªæ£€æµ‹ï¼‰
- workflow: æ‰§è¡Œå®Œæ•´å·¥ä½œæµ

è¯¦ç»†å¸®åŠ©ï¼š
python main.py -h
python main.py [æ¨¡å—åç§°] -h

ç‰ˆæœ¬ï¼š1.0.0
"""

import argparse
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonæœç´¢è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.common.logger_utils import setup_logger, get_logger, log_exception  # noqa: E402
from src.common.config_utils import load_config, get_directory, validate_directories  # noqa: E402
from src.extend_mode.core import run_extend_sub_flow  # noqa: E402
from src.extract_mode.core import run_extract_sub_flow  # noqa: E402
from src.decompile_mode.core import run_decompile_sub_flow  # noqa: E402

# æ·»åŠ æ–°çš„æ¨¡å—å¯¼å…¥
from src.extend_mode import (
    extract_mapping_rules,
    process_unmapped_content,
    detect_and_resolve_conflicts,
    generate_translation_rules,
    update_translation_rules,
    run_complete_workflow,
    auto_generate_rules,
    manage_rules
)  # noqa: E402

# è®¾ç½®å…¨å±€æ—¥å¿—è®°å½•å™¨
logger = setup_logger("modlocale")


# ä¿®æ”¹select_main_modeå‡½æ•°ï¼Œç§»é™¤é«˜çº§æ¨¡å¼çš„é‡å¤é€‰é¡¹
def select_main_mode() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©ä¸»æ¨¡å¼(Extractæˆ–Extendæˆ–Decompileæˆ–æ–‡ä»¶ç®¡ç†æ¨¡å¼æˆ–æ˜ å°„è§„åˆ™ç®¡ç†æˆ–å®Œæ•´å·¥ä½œæµ)

    Returns:
        str: é€‰æ‹©çš„æ¨¡å¼ç¼–å·("1"ã€"2"ã€"3"ã€"4"ã€"5"æˆ–"6")
    """
    print("===========================================")
    print("               ModLocale")
    print("===========================================")
    print("è¯·é€‰æ‹©æ“ä½œæ¨¡å¼ï¼š")
    print("1. Extractæ¨¡å¼(ä»…æå–å­—ç¬¦ä¸²ï¼Œé»˜è®¤ç®€æ´æ¨¡å¼)")
    print("2. Extendæ¨¡å¼(æ‰§è¡Œæ˜ å°„æµç¨‹ï¼Œé»˜è®¤ç®€æ´æ¨¡å¼)")
    print("3. Decompileæ¨¡å¼(æ‰§è¡ŒJARæ–‡ä»¶åç¼–è¯‘/æå–)")
    print("4. æ–‡ä»¶ç®¡ç†æ¨¡å¼(æ–‡ä»¶å¤¹åˆ›å»ºã€é‡å‘½åã€å¤‡ä»½æ¢å¤)")
    print("5. æ˜ å°„è§„åˆ™ç®¡ç†ï¼ˆç”Ÿæˆ/æ›´æ–°/å†²çªæ£€æµ‹ï¼‰")
    print("6. è¿è¡Œå®Œæ•´å·¥ä½œæµ")
    print("===========================================")

    while True:
        choice = input("è¾“å…¥æ•°å­—(1/2/3/4/5/6ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not choice:  # ç›´æ¥å›è½¦ï¼Œé»˜è®¤é€‰1
            return "1"
        elif choice in ["1", "2", "3", "4", "5", "6"]:
            return choice
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(1/2/3/4/5/6)ï¼")


# ç®€åŒ–select_extract_sub_flowå‡½æ•°ï¼Œç¡®ä¿è¾“å‡ºè·¯å¾„æ­£ç¡®
def select_extract_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©Extractæ¨¡å¼çš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹
    """
    # æ£€æµ‹sourceæ–‡ä»¶å¤¹
    detection_result = check_source_folders()
    
    # äºŒçº§èœå•ï¼šç›´æ¥è¿›å…¥ç®€æ´æ¨¡å¼çš„è¯­è¨€é€‰æ‹©
    print("\n==========================================")
    print("        Extractæ¨¡å¼ - ç®€æ´æ¨¡å¼(è‡ªåŠ¨æ£€æµ‹)")
    print("==========================================")
    
    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
    print("ğŸ” æ­£åœ¨æ£€æµ‹ä¸»ç›®å½•ä¸‹çš„sourceæ–‡ä»¶å¤¹...")
    if detection_result["english_src"]:
        print("âœ… æ£€æµ‹åˆ°source/English/srcæ–‡ä»¶å¤¹(å«è‹±æ–‡æ–‡æœ¬)ï¼Œå°†ä¼˜å…ˆæå–æ­¤å¤„å†…å®¹")
    elif detection_result["english_jar"]:
        print("âœ… æ£€æµ‹åˆ°source/English/jarsæ–‡ä»¶å¤¹ï¼Œå°†åç¼–è¯‘æœªæ±‰åŒ–jaråŒ…")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°source/English/srcæˆ–jarsæ–‡ä»¶å¤¹ï¼Œè¯·å…ˆå‡†å¤‡æºæ–‡ä»¶")
    
    from src.common.config_utils import get_directory
    output_root = get_directory("output")
    if output_root:
        print(f"ğŸ“¤ æå–ç»“æœå°†ä¿å­˜åˆ°ï¼š{output_root}/Extract_English/")
    else:
        print("ğŸ“¤ æå–ç»“æœå°†ä¿å­˜åˆ°ï¼šä¸»ç›®å½•/File/output/Extract_English/")
    print("   åŒ…å«ï¼šå­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶ + æµç¨‹æŠ¥å‘Š + mod_info.json")
    print("==========================================")
    print("è¯·é€‰æ‹©æå–è¯­è¨€ï¼š")
    print("1. æå–è‹±æ–‡(ä¼˜å…ˆæ£€æµ‹src/æ— åˆ™åç¼–è¯‘æœªæ±‰åŒ–jar)")
    print("2. æå–ä¸­æ–‡(ä¼˜å…ˆæ£€æµ‹src/æ— åˆ™åç¼–è¯‘å·²æ±‰åŒ–jar)")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("==========================================")

    while True:
        lang_choice = input("è¾“å…¥æ•°å­—(1/2/0ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not lang_choice:  # ç›´æ¥å›è½¦ï¼Œé»˜è®¤é€‰1
            return "è‹±æ–‡æå–æµç¨‹"
        elif lang_choice == "1":
            return "è‹±æ–‡æå–æµç¨‹"
        elif lang_choice == "2":
            return "ä¸­æ–‡æå–æµç¨‹"
        elif lang_choice == "0":
            return "return_to_previous"
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(1/2/0)ï¼")


# ç®€åŒ–select_extend_sub_flowå‡½æ•°ï¼Œç¡®ä¿è¾“å‡ºè·¯å¾„æ­£ç¡®
def select_extend_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©Extendæ¨¡å¼çš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹
    """
    # æ£€æµ‹sourceæ–‡ä»¶å¤¹
    detection_result = check_source_folders()
    
    # äºŒçº§èœå•ï¼šç›´æ¥è¿›å…¥ç®€æ´æ¨¡å¼çš„æ˜ å°„æ–¹å‘é€‰æ‹©
    print("\n==========================================")
    print("        Extendæ¨¡å¼ - ç®€æ´æ¨¡å¼")
    print("==========================================")
    
    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
    print("ğŸ” æ­£åœ¨æ£€æµ‹ä¸»ç›®å½•ä¸‹çš„sourceå’Œruleæ–‡ä»¶å¤¹...")
    from src.common.config_utils import get_directory
    rule_path = get_directory("rules")
    if rule_path and os.path.exists(rule_path):
        print(f"âœ… æ£€æµ‹åˆ°ruleæ–‡ä»¶å¤¹ï¼Œå°†ä¼˜å…ˆä½¿ç”¨æ˜ å°„è§„åˆ™æ–‡ä»¶ï¼š{rule_path}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°ruleæ–‡ä»¶å¤¹ï¼Œå°†ç›´æ¥æ£€æµ‹src/jarsæ–‡ä»¶å¤¹")
    
    if detection_result["chinese_src"] or detection_result["chinese_jar"]:
        print("âœ… æ£€æµ‹åˆ°source/Chineseæ–‡ä»¶å¤¹ï¼Œå¯è¿›è¡Œä¸­æ–‡ç›¸å…³æ˜ å°„")
    if detection_result["english_src"] or detection_result["english_jar"]:
        print("âœ… æ£€æµ‹åˆ°source/Englishæ–‡ä»¶å¤¹ï¼Œå¯è¿›è¡Œè‹±æ–‡ç›¸å…³æ˜ å°„")
    
    output_root = get_directory("output")
    if output_root:
        print(f"ğŸ“¤ æ˜ å°„ç»“æœå°†ä¿å­˜åˆ°ï¼š{output_root}/Extend_xxx/")
    else:
        print("ğŸ“¤ æ˜ å°„ç»“æœå°†ä¿å­˜åˆ°ï¼šä¸»ç›®å½•/File/output/Extend_xxx/")
    print("   åŒ…å«ï¼šæ˜ å°„åçš„æºæ–‡ä»¶å¤¹ + å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶ + æµç¨‹æŠ¥å‘Š + mod_info.json")
    print("==========================================")
    
    print("è¯·é€‰æ‹©æ˜ å°„æ–¹å‘ï¼š")
    print("1. ä¸­æ–‡æ˜ å°„åˆ°è‹±æ–‡(ä¼˜å…ˆæ£€æµ‹æ˜ å°„è§„åˆ™/æ— åˆ™è‡ªåŠ¨æ£€æµ‹src/jars)")
    print("2. è‹±æ–‡æ˜ å°„åˆ°ä¸­æ–‡(ä¼˜å…ˆæ£€æµ‹æ˜ å°„è§„åˆ™/æ— åˆ™è‡ªåŠ¨æ£€æµ‹src/jars)")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("==========================================")
    
    while True:
        direction_choice = input("è¾“å…¥æ•°å­—(1/2/0ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not direction_choice:  # ç›´æ¥å›è½¦ï¼Œé»˜è®¤é€‰1
            return "å·²æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹"
        elif direction_choice == "1":
            mapping_direction = "ä¸­æ–‡â†’è‹±æ–‡"
            
            # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
            print(f"\n==========================================")
            print(f"        Extendæ¨¡å¼ - [{mapping_direction}] ç®€æ´æ¨¡å¼")
            print("==========================================")
            print("æ­£åœ¨æ‰§è¡Œï¼šä¼˜å…ˆæ£€æµ‹æ˜ å°„è§„åˆ™æ–‡ä»¶å¤¹â†’æ£€æµ‹src/jarsæ–‡ä»¶å¤¹â†’æ˜ å°„å­—ç¬¦ä¸²")
            print("æµç¨‹æ­¥éª¤ï¼šåˆ›å»ºæ–‡ä»¶å¤¹â†’é‡å‘½åæ¨¡ç»„â†’æ¢å¤å¤‡ä»½â†’å­—ç¬¦ä¸²æ˜ å°„...")
            
            return "å·²æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹"
        elif direction_choice == "2":
            mapping_direction = "è‹±æ–‡â†’ä¸­æ–‡"
            
            # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
            print(f"\n==========================================")
            print(f"        Extendæ¨¡å¼ - [{mapping_direction}] ç®€æ´æ¨¡å¼")
            print("==========================================")
            print("æ­£åœ¨æ‰§è¡Œï¼šä¼˜å…ˆæ£€æµ‹æ˜ å°„è§„åˆ™æ–‡ä»¶å¤¹â†’æ£€æµ‹src/jarsæ–‡ä»¶å¤¹â†’æ˜ å°„å­—ç¬¦ä¸²")
            print("æµç¨‹æ­¥éª¤ï¼šåˆ›å»ºæ–‡ä»¶å¤¹â†’é‡å‘½åæ¨¡ç»„â†’æ¢å¤å¤‡ä»½â†’å­—ç¬¦ä¸²æ˜ å°„...")
            
            return "å·²æœ‰è‹±æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹"
        elif direction_choice == "0":
            return "return_to_previous"
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(1/2/0)ï¼")


# ç®€åŒ–select_decompile_sub_flowå‡½æ•°ï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°
def select_decompile_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©Decompileæ¨¡å¼çš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹
    """
    # äºŒçº§èœå•ï¼šç›´æ¥è¿›å…¥Decompileæ¨¡å¼çš„å­æµç¨‹é€‰æ‹©
    print("\n==========================================")
    print("        Decompileæ¨¡å¼ - æ“ä½œé€‰æ‹©")
    print("==========================================")
    
    print("ğŸ“‹ åç¼–è¯‘æ¨¡å¼æ”¯æŒä»¥ä¸‹æ“ä½œï¼š")
    print("1. åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶")
    print("2. åç¼–è¯‘ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶")
    print("3. æå–å•ä¸ªJARæ–‡ä»¶å†…å®¹")
    print("4. æå–ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶å†…å®¹")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("===========================================")
    
    while True:
        decompile_choice = input("è¾“å…¥æ•°å­—(0-4ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not decompile_choice:  # ç›´æ¥å›è½¦ï¼Œé»˜è®¤é€‰1
            decompile_choice = "1"
        
        if decompile_choice == "0":
            return "return_to_previous"
        elif decompile_choice in ["1", "2", "3", "4"]:
            sub_flows = {
                "1": "åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶",
                "2": "åç¼–è¯‘ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶",
                "3": "æå–å•ä¸ªJARæ–‡ä»¶å†…å®¹",
                "4": "æå–ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶å†…å®¹"
            }
            selected_sub_flow = sub_flows[decompile_choice]
            
            # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
            print(f"\næ‰§è¡Œé…ç½®ï¼š")
            print(f"æ¨¡å¼ï¼šDecompile")
            print(f"æµç¨‹ï¼š{selected_sub_flow}")
            print("===========================================")
            
            return selected_sub_flow
        else:
            print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(0-4)ï¼")


# ç§»é™¤toggle_advanced_modeå‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ç§»é™¤set_main_languageå‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ç§»é™¤toggle_process_granularityå‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ç§»é™¤toggle_precheck_mechanismå‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ç§»é™¤advanced_settingså‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ç§»é™¤select_cli_settingså‡½æ•°ï¼Œç®€åŒ–ä»£ç 


# ä¿®æ”¹check_project_structureå‡½æ•°ï¼Œç¡®ä¿ç›®å½•ç»“æ„ç¬¦åˆé…ç½®
def check_project_structure() -> bool:
    """
    æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦çš„é¡¹ç›®ç»“æ„ï¼Œä¸¥æ ¼æŒ‰ç…§æ¡†æ¶æ–‡æ¡£ç”Ÿæˆç›®å½•

    Returns:
        bool: é¡¹ç›®ç»“æ„æ£€æŸ¥ç»“æœ
    """
    logger.info("æ£€æŸ¥é¡¹ç›®ç»“æ„...")
    
    # è·å–å·¥å…·æ ¹ç›®å½•
    tool_root = get_directory("tool_root")
    if not tool_root:
        # å›é€€åˆ°å½“å‰è„šæœ¬çš„é¡¹ç›®æ ¹ç›®å½•
        tool_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    # å®šä¹‰ File ç›®å½•è·¯å¾„(åœ¨å·¥å…·æ ¹ç›®å½•ä¸‹)
    localization_file_path = os.path.join(tool_root, "File")
    
    # å®šä¹‰ File ä¸‹çš„å¿…è¦æ–‡ä»¶å¤¹ç»“æ„ - ä¸¥æ ¼æŒ‰ç…§æ¡†æ¶æ–‡æ¡£
    localization_folders = [
        # æºæ–‡ä»¶ç›®å½•ç»“æ„
        os.path.join(localization_file_path, "source"),
        os.path.join(localization_file_path, "source", "English"),
        os.path.join(localization_file_path, "source", "Chinese"),
        # æºæ–‡ä»¶å¤‡ä»½ç›®å½•ç»“æ„
        os.path.join(localization_file_path, "source_backup"),
        os.path.join(localization_file_path, "source_backup", "English"),
        os.path.join(localization_file_path, "source_backup", "Chinese"),
        # æ˜ å°„è§„åˆ™ç›®å½•ç»“æ„
        os.path.join(localization_file_path, "rule"),
        os.path.join(localization_file_path, "rule", "English"),
        os.path.join(localization_file_path, "rule", "Chinese"),
        # è¾“å‡ºç›®å½•ç»“æ„
        os.path.join(localization_file_path, "output"),
        # Extractè¾“å‡ºç›®å½•
        os.path.join(localization_file_path, "output", "Extract_Chinese"),
        os.path.join(localization_file_path, "output", "Extract_English"),
        # Extendè¾“å‡ºç›®å½•
        os.path.join(localization_file_path, "output", "Extend_en2zh"),
        os.path.join(localization_file_path, "output", "Extend_zh2en"),
        # æ˜ å°„åmodæ–‡ä»¶å¤¹
        os.path.join(localization_file_path, "mapped_mods"),
    ]
    
    try:
        # åˆ›å»º Localization_File ç›®å½•ç»“æ„
        for folder in localization_folders:
            if not os.path.exists(folder):
                os.makedirs(folder, exist_ok=True)
                logger.info(f"åˆ›å»ºæ–‡ä»¶å¤¹: {folder}")
        
        logger.info("é¡¹ç›®ç»“æ„æ£€æŸ¥å®Œæˆï¼Œä¸¥æ ¼æŒ‰ç…§æ¡†æ¶æ–‡æ¡£ç”Ÿæˆç›®å½•")
        return True
    except Exception as e:
        logger.error(f"é¡¹ç›®ç»“æ„æ£€æŸ¥å¤±è´¥: {str(e)}")
        print(f"[ERROR] é¡¹ç›®ç»“æ„æ£€æŸ¥å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


# ä¿®æ”¹show_welcome_guideå‡½æ•°ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
def show_welcome_guide():
    """
    æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯å’Œæ–‡ä»¶å¤¹ç»“æ„å¼•å¯¼
    """
    print("==========================================")
    print("                ModLocale")
    print("==========================================")
    print("ğŸ“Œ ã€å‰ç½®æ£€æŸ¥ã€‘è¯·ç¡®è®¤å·²æŒ‰ä»¥ä¸‹ç»“æ„å­˜æ”¾æ–‡ä»¶ï¼š")
    print("ModLocale/File/")
    print("â”œâ”€ source/English/(src/jars) ï½œ è‹±æ–‡æºæ–‡ä»¶")
    print("â”œâ”€ source/Chinese/(src/jars) ï½œ ä¸­æ–‡æºæ–‡ä»¶")
    print("â”œâ”€ rule/(å¯é€‰)               ï½œ æ˜ å°„è§„åˆ™æ–‡ä»¶")
    print("â””â”€ output/(è‡ªåŠ¨ç”Ÿæˆ)         ï½œ ç»“æœè¾“å‡ºåŒº")
    print("ğŸ’¡ å¿˜è®°ç»“æ„ï¼Ÿè¾“å…¥ã€Œhelpã€æŸ¥çœ‹è¯¦ç»†å¼•å¯¼ï¼Œè¾“å…¥ã€Œstartã€è¿›å…¥ä¸»èœå•")
    print("==========================================")
    print("è¾“å…¥æŒ‡ä»¤(help/start)ï¼š")
    
    # å¤„ç†ç”¨æˆ·è¾“å…¥
    while True:
        choice = input().strip().lower()
        if choice == "start":
            break
        elif choice == "help":
            show_detailed_guide()
        else:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ã€Œhelpã€æˆ–ã€Œstartã€ï¼š")


# ç®€åŒ–show_detailed_guideå‡½æ•°ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
def show_detailed_guide():
    """
    æ˜¾ç¤ºè¯¦ç»†çš„ç”¨æˆ·å¼•å¯¼
    """
    print("\n# ModLocale - å‹å¥½ç”¨æˆ·å¼•å¯¼æ‰‹å†Œ")
    print("(é€‚é…ç»ˆç«¯äº¤äº’ï¼Œå…¨ç¨‹åµŒå…¥å¼å¼•å¯¼ï¼Œé€šä¿—æ˜“æ‡‚+æ­¥éª¤åŒ–ï¼Œé™ä½æ“ä½œé—¨æ§›)")
    print("\n## ğŸŒŸ æ¬¢è¿ä½¿ç”¨ModLocaleï¼")
    print("åœ¨å¼€å§‹æ“ä½œå‰ï¼Œè¯·å…ˆå®Œæˆã€Œæ–‡ä»¶å¤¹å‡†å¤‡ã€(30ç§’å³å¯æå®š)ï¼Œå·¥å…·ä¼šä¸¥æ ¼æŒ‰ç…§ä½ å­˜æ”¾çš„æ–‡ä»¶å¤¹ç»“æ„è¯†åˆ«æ–‡ä»¶ï¼Œ")
    print("è¾“å‡ºå†…å®¹ä¹Ÿä¼šç»Ÿä¸€æ•´ç†åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå…¨ç¨‹æ— éœ€æ‰‹åŠ¨ç¿»æ‰¾ï½")
    print("\n## ğŸ“‚ ç¬¬ä¸€æ­¥ï¼šä¸»ç›®å½•ç»“æ„å‡†å¤‡(å¿…çœ‹ï¼)")
    print("è¯·å…ˆåœ¨ModLocaleç›®å½•ä¸‹åˆ›å»ºã€ŒFileã€æ–‡ä»¶å¤¹ï¼Œå¹¶æŒ‰ä»¥ä¸‹ç»“æ„å­˜æ”¾æ–‡ä»¶å¤¹ï¼Œ")
    print("**å‘½åå¿…é¡»ä¸¥æ ¼ä¸€è‡´**(å·¥å…·è‡ªåŠ¨è¯†åˆ«ï¼Œé”™å­—ä¼šå¯¼è‡´æ£€æµ‹å¤±è´¥)ï¼š")
    print("""```
ModLocale/ (å·¥å…·ä¸»ç›®å½•)
â”œâ”€ File/ (æºæ–‡ä»¶å­˜æ”¾åŒºï¼Œå·¥å…·è‡ªåŠ¨åˆ›å»ºï¼)
â”‚  â”œâ”€ source/ (æºæ–‡ä»¶å­˜æ”¾åŒº)
â”‚  â”‚  â”œâ”€ English/ (è‹±æ–‡æºæ–‡ä»¶)
â”‚  â”‚  â”‚  â”œâ”€ src/ (å¯é€‰ï¼šå·²æœ‰è‹±æ–‡æºç æ–‡ä»¶å¤¹ï¼Œæ”¾å¾…æå–çš„è‹±æ–‡æ–‡æœ¬æ–‡ä»¶)
â”‚  â”‚  â”‚  â””â”€ jars/ (å¯é€‰ï¼šå¾…åç¼–è¯‘çš„è‹±æ–‡jaråŒ…ï¼Œæœªæ±‰åŒ–ç‰ˆ)
â”‚  â”‚  â””â”€ Chinese/ (ä¸­æ–‡æºæ–‡ä»¶)
â”‚  â”‚     â”œâ”€ src/ (å¯é€‰ï¼šå·²æœ‰ä¸­æ–‡åŒ–æºç æ–‡ä»¶å¤¹ï¼Œæ”¾å¾…æå–/æ˜ å°„çš„ä¸­æ–‡æ–‡æœ¬æ–‡ä»¶)
â”‚  â”‚     â””â”€ jars/ (å¯é€‰ï¼šå¾…åç¼–è¯‘çš„ä¸­æ–‡jaråŒ…ï¼Œå·²æ±‰åŒ–ç‰ˆ)
â”‚  â”œâ”€ rule/ (æ˜ å°„è§„åˆ™å­˜æ”¾åŒºï¼ŒExtendæ¨¡å¼ä¸“å±ï¼Œå¯é€‰)
â”‚  â”‚  â”œâ”€ English/ (è‹±æ–‡æ˜ å°„è§„åˆ™æ–‡ä»¶)
â”‚  â”‚  â””â”€ Chinese/ (ä¸­æ–‡æ˜ å°„è§„åˆ™æ–‡ä»¶)
â”‚  â””â”€ output/ (å·¥å…·è‡ªåŠ¨ç”Ÿæˆï¼Œæ— éœ€åˆ›å»ºï¼æ‰€æœ‰æå–/æ˜ å°„ç»“æœ+æŠ¥å‘Šéƒ½åœ¨è¿™é‡Œ)
â””â”€ src/ (å·¥å…·æºä»£ç )
   â”œâ”€ common/ (é€šç”¨æ¨¡å—)
   â”œâ”€ decompile_mode/ (åç¼–è¯‘æ¨¡å¼)
   â”œâ”€ extract_mode/ (æå–æ¨¡å¼)
   â”œâ”€ extend_mode/ (æ˜ å°„æ¨¡å¼)
   â””â”€ init_mode/ (åˆå§‹åŒ–æ¨¡å¼)
```""")
    print("\n### âœ¨ æ ¸å¿ƒå¼•å¯¼ï¼šä¸åŒæ¨¡å¼å¯¹åº”å“ªäº›æ–‡ä»¶å¤¹ï¼Ÿ")
    print("| æ“ä½œæ¨¡å¼       | éœ€å‡†å¤‡çš„æºæ–‡ä»¶å¤¹       | å·¥å…·ä¼šè‡ªåŠ¨å¤„ç†ä»€ä¹ˆï¼Ÿ|")
    print("|----------------|------------------------|---------------------------------------------|")
    print("| Extract-æå–è‹±æ–‡ | ModLocale/File/source/English/src æˆ– ModLocale/File/source/English/jars | ä¼˜å…ˆè¯»srcï¼Œæ— åˆ™åç¼–è¯‘jarï¼Œç»“æœå­˜åˆ°ModLocale/File/output/Extract_English |")
    print("| Extract-æå–ä¸­æ–‡ | ModLocale/File/source/Chinese/src æˆ– ModLocale/File/source/Chinese/jars | ä¼˜å…ˆè¯»srcï¼Œæ— åˆ™åç¼–è¯‘jarï¼Œç»“æœå­˜åˆ°ModLocale/File/output/Extract_Chinese |")
    print("| Extend-ä¸­æ˜ å°„è‹± | ModLocale/File/source/Chinese/xxx + ModLocale/File/rule/Chinese/xxx | ä¼˜å…ˆè¯»æ˜ å°„è§„åˆ™ï¼Œæ— åˆ™è¯»src/jarsï¼Œç»“æœå­˜åˆ°ModLocale/File/output/Extend_Zh2En |")
    print("| Extend-è‹±æ˜ å°„ä¸­ | ModLocale/File/source/English/xxx + ModLocale/File/rule/English/xxx | ä¼˜å…ˆè¯»æ˜ å°„è§„åˆ™ï¼Œæ— åˆ™è¯»src/jarsï¼Œç»“æœå­˜åˆ°ModLocale/File/output/Extend_En2Zh |")
    print("\nğŸ’¡ æç¤ºï¼šModLocale/File ç›®å½•ä¼šåœ¨å·¥å…·å¯åŠ¨æ—¶è‡ªåŠ¨åˆ›å»ºï¼")
    print("\nè¾“å…¥ã€Œstartã€è¿›å…¥ä¸»èœå•ï¼Œè¾“å…¥ã€Œhelpã€é‡æ–°æŸ¥çœ‹å¼•å¯¼ï¼š")


# ä¿®æ”¹check_source_folderså‡½æ•°ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
def check_source_folders() -> dict:
    """
    æ£€æŸ¥sourceæ–‡ä»¶å¤¹ä¸‹çš„srcå’Œjarså­æ–‡ä»¶å¤¹

    Returns:
        dict: æ£€æµ‹ç»“æœ
    """
    result = {
        "english_src": False,
        "english_jar": False,
        "chinese_src": False,
        "chinese_jar": False
    }
    
    # ä»é…ç½®ä¸­è·å–sourceç›®å½•è·¯å¾„
    source_path = get_directory("source")
    if not source_path:
        logger.error("è·å–sourceç›®å½•è·¯å¾„å¤±è´¥")
        return result
    
    # æ£€æŸ¥è‹±æ–‡æºæ–‡ä»¶å¤¹
    english_path = os.path.join(source_path, "English")
    if os.path.exists(english_path):
        if os.path.exists(os.path.join(english_path, "src")):
            result["english_src"] = True
        if os.path.exists(os.path.join(english_path, "jars")):
            result["english_jar"] = True
    
    # æ£€æŸ¥ä¸­æ–‡æºæ–‡ä»¶å¤¹
    chinese_path = os.path.join(source_path, "Chinese")
    if os.path.exists(chinese_path):
        if os.path.exists(os.path.join(chinese_path, "src")):
            result["chinese_src"] = True
        if os.path.exists(os.path.join(chinese_path, "jars")):
            result["chinese_jar"] = True
    
    return result


# ç®€åŒ–show_output_guideå‡½æ•°ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
# æ·»åŠ æ–‡ä»¶ç®¡ç†æ¨¡å¼çš„å­æµç¨‹é€‰æ‹©å‡½æ•°
def select_file_management_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©æ–‡ä»¶ç®¡ç†æ¨¡å¼çš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹
    """
    print("\n==========================================")
    print("        æ–‡ä»¶ç®¡ç†æ¨¡å¼ - æ“ä½œé€‰æ‹©")
    print("==========================================")
    print("è¯·é€‰æ‹©æ–‡ä»¶ç®¡ç†æ“ä½œï¼š")
    print("1. åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„")
    print("2. é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹")
    print("3. æ¢å¤å¤‡ä»½")
    print("4. æ‰§è¡Œå®Œæ•´æ–‡ä»¶ç®¡ç†æµç¨‹")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("===========================================")

    while True:
        choice = input("è¾“å…¥æ•°å­—(0-4ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰4)ï¼š").strip()
        if not choice:
            choice = "4"
        if choice == "0":
            return "return_to_previous"
        elif choice in ["1", "2", "3", "4"]:
            sub_flows = {
                "1": "åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„",
                "2": "é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹",
                "3": "æ¢å¤å¤‡ä»½",
                "4": "æ‰§è¡Œå®Œæ•´æ–‡ä»¶ç®¡ç†æµç¨‹"
            }
            return sub_flows[choice]
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(0-4)ï¼")

# æ·»åŠ æ–‡ä»¶ç®¡ç†æ¨¡å¼çš„æ‰§è¡Œå‡½æ•°
def run_file_management_sub_flow(sub_flow: str, base_path: str) -> dict:
    """
    è¿è¡Œæ–‡ä»¶ç®¡ç†å­æµç¨‹

    Args:
        sub_flow: å­æµç¨‹ç±»å‹
        base_path: åŸºç¡€è·¯å¾„

    Returns:
        dict: å¤„ç†ç»“æœ
    """
    logger.info(f"æ‰§è¡Œæ–‡ä»¶ç®¡ç†å­æµç¨‹ï¼š{sub_flow}")
    
    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    from src.init_mode import run_init_tasks
    from src.common.file_utils import rename_mod_folders, restore_backup
    from src.common.config_utils import get_directory
    
    result = {
        "status": "success",
        "data": {
            "total_count": 0,
            "success_count": 0,
            "fail_count": 0,
            "fail_reasons": []
        }
    }
    
    try:
        # è·å–å¿…è¦çš„ç›®å½•è·¯å¾„
        tool_root = get_directory("tool_root")
        source_path = get_directory("source")
        backup_path = get_directory("source_backup")
        
        if sub_flow == "åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„" or sub_flow == "æ‰§è¡Œå®Œæ•´æ–‡ä»¶ç®¡ç†æµç¨‹":
            # æ‰§è¡Œåˆå§‹åŒ–ä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ›å»ºé¡¹ç›®ç»“æ„
            logger.info("æ‰§è¡Œåˆå§‹åŒ–ä»»åŠ¡ï¼Œåˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„")
            init_result = run_init_tasks(tool_root)
            if init_result['status'] == 'fail':
                result['status'] = 'fail'
                result['data']['fail_count'] += 1
                result['data']['fail_reasons'].append("åˆå§‹åŒ–é¡¹ç›®ç»“æ„å¤±è´¥")
            else:
                result['data']['success_count'] += 1
        
        if sub_flow == "é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹" or sub_flow == "æ‰§è¡Œå®Œæ•´æ–‡ä»¶ç®¡ç†æµç¨‹":
            # é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹
            logger.info("é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹")
            if rename_mod_folders(source_path):
                result['data']['success_count'] += 1
            else:
                result['status'] = 'fail'
                result['data']['fail_count'] += 1
                result['data']['fail_reasons'].append("é‡å‘½åæ¨¡ç»„æ–‡ä»¶å¤¹å¤±è´¥")
            
            if rename_mod_folders(backup_path):
                result['data']['success_count'] += 1
            else:
                result['status'] = 'fail'
                result['data']['fail_count'] += 1
                result['data']['fail_reasons'].append("é‡å‘½åå¤‡ä»½æ–‡ä»¶å¤¹å¤±è´¥")
        
        if sub_flow == "æ¢å¤å¤‡ä»½":
            # æ¢å¤å¤‡ä»½
            logger.info("æ¢å¤å¤‡ä»½")
            if restore_backup(backup_path, source_path):
                result['data']['success_count'] += 1
            else:
                result['status'] = 'fail'
                result['data']['fail_count'] += 1
                result['data']['fail_reasons'].append("æ¢å¤å¤‡ä»½å¤±è´¥")
        
        result['data']['total_count'] = result['data']['success_count'] + result['data']['fail_count']
        
        print(f"\næ–‡ä»¶ç®¡ç†æ“ä½œå®Œæˆï¼")
        print(f"æ€»è®¡ï¼š{result['data']['total_count']} é¡¹æ“ä½œ")
        print(f"æˆåŠŸï¼š{result['data']['success_count']} é¡¹")
        print(f"å¤±è´¥ï¼š{result['data']['fail_count']} é¡¹")
        if result['data']['fail_reasons']:
            print(f"å¤±è´¥åŸå› ï¼š")
            for reason in result['data']['fail_reasons']:
                print(f"  - {reason}")
        
        return result
    except Exception as e:
        logger.exception(f"æ‰§è¡Œæ–‡ä»¶ç®¡ç†å­æµç¨‹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        result['status'] = 'fail'
        result['data']['fail_count'] = 1
        result['data']['fail_reasons'].append(str(e))
        result['data']['total_count'] = 1
        return result

# æ·»åŠ é€‰æ‹©modæ–‡ä»¶å¤¹çš„å‡½æ•°
def select_mod_folder() -> str:
    """
    è‡ªåŠ¨è¯†åˆ«sourceæ–‡ä»¶å¤¹ä¸‹çš„modå­ç›®å½•ï¼Œå¹¶æä¾›äº¤äº’å¼é€‰æ‹©ç•Œé¢

    Returns:
        str: ç”¨æˆ·é€‰æ‹©çš„modæ–‡ä»¶å¤¹è·¯å¾„ï¼Œè‹¥å–æ¶ˆåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    try:
        # ä»é…ç½®ä¸­è·å–sourceç›®å½•è·¯å¾„
        source_path = get_directory("source")
        if not source_path:
            print("[ERROR] è·å–sourceç›®å½•è·¯å¾„å¤±è´¥")
            logger.error("è·å–sourceç›®å½•è·¯å¾„å¤±è´¥")
            return ""
        
        # æ£€æŸ¥sourceç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(source_path):
            print(f"[ERROR] sourceç›®å½•ä¸å­˜åœ¨: {source_path}")
            logger.error(f"sourceç›®å½•ä¸å­˜åœ¨: {source_path}")
            return ""
        
        # æ”¶é›†æ‰€æœ‰modæ–‡ä»¶å¤¹
        mod_folders = []
        
        # éå†sourceç›®å½•ä¸‹çš„æ‰€æœ‰è¯­è¨€å­æ–‡ä»¶å¤¹
        for lang_folder in os.listdir(source_path):
            lang_path = os.path.join(source_path, lang_folder)
            if os.path.isdir(lang_path):
                # éå†è¯­è¨€å­æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¯†åˆ«modæ–‡ä»¶å¤¹
                for mod_folder in os.listdir(lang_path):
                    mod_folder_path = os.path.join(lang_path, mod_folder)
                    if os.path.isdir(mod_folder_path):
                        mod_folders.append({
                            "name": mod_folder,
                            "path": mod_folder_path,
                            "language": lang_folder
                        })
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°modæ–‡ä»¶å¤¹
        if not mod_folders:
            print(f"[ERROR] æœªæ‰¾åˆ°ä»»ä½•modæ–‡ä»¶å¤¹")
            print(f"[INFO] è¯·æ£€æŸ¥sourceç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®: {source_path}")
            print(f"[INFO] é¢„æœŸç»“æ„: source/{lang_folder}/{mod_name}")
            logger.error(f"æœªæ‰¾åˆ°ä»»ä½•modæ–‡ä»¶å¤¹ï¼Œsourceç›®å½•: {source_path}")
            return ""
        
        # ä»¥æ¸…æ™°çš„åˆ—è¡¨å½¢å¼å‘ˆç°ç»™ç”¨æˆ·
        print("\n==========================================")
        print("        å¯ç”¨modæ–‡ä»¶å¤¹åˆ—è¡¨")
        print("==========================================")
        print(f"æ‰¾åˆ° {len(mod_folders)} ä¸ªå¯ç”¨çš„modæ–‡ä»¶å¤¹ï¼š")
        print("==========================================")
        
        for i, mod in enumerate(mod_folders, 1):
            print(f"{i}. {mod['name']} (è¯­è¨€: {mod['language']})")
            print(f"   è·¯å¾„: {mod['path']}")
        
        print("0. è¿”å›ä¸Šä¸€çº§èœå•")
        print("==========================================")
        
        # æä¾›äº¤äº’å¼é€‰æ‹©ç•Œé¢
        while True:
            choice = input("è¯·é€‰æ‹©ä¸€ä¸ªmodæ–‡ä»¶å¤¹ï¼ˆè¾“å…¥æ•°å­—ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1ï¼‰ï¼š").strip()
            if not choice:
                choice = "1"
            
            if choice == "0":
                return ""
            
            try:
                index = int(choice) - 1
                if 0 <= index < len(mod_folders):
                    selected_mod = mod_folders[index]
                    print(f"\n==========================================")
                    print(f"        å·²é€‰æ‹©modæ–‡ä»¶å¤¹")
                    print(f"==========================================")
                    print(f"åç§°: {selected_mod['name']}")
                    print(f"è¯­è¨€: {selected_mod['language']}")
                    print(f"è·¯å¾„: {selected_mod['path']}")
                    print("==========================================")
                    
                    # ç¡®è®¤ç”¨æˆ·é€‰æ‹©
                    confirm = input("æ˜¯å¦ç¡®è®¤é€‰æ‹©ï¼Ÿ(y/nï¼Œé»˜è®¤y)ï¼š").strip().lower()
                    if confirm in ["", "y", "yes"]:
                        return selected_mod['path']
                    else:
                        print("\né‡æ–°é€‰æ‹©modæ–‡ä»¶å¤¹...")
                else:
                    print(f"[ERROR] è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥1-{len(mod_folders)}ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("[ERROR] è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—")
    
    except PermissionError:
        print("[ERROR] æƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®ç›®å½•")
        logger.error("æƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®ç›®å½•")
        return ""
    except Exception as e:
        print(f"[ERROR] é€‰æ‹©modæ–‡ä»¶å¤¹æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        logger.exception(f"é€‰æ‹©modæ–‡ä»¶å¤¹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return ""

# ç®€åŒ–show_output_guideå‡½æ•°ï¼Œç¡®ä¿è¾“å‡ºè·¯å¾„æ­£ç¡®
def show_output_guide(output_path: str, mode: str, language: str):
    """
    æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶å¤¹å¼•å¯¼

    Args:
        output_path: è¾“å‡ºè·¯å¾„
        mode: æ“ä½œæ¨¡å¼
        language: è¯­è¨€ç±»å‹
    """
    print("\nğŸ‰ æ“ä½œå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³ï¼š")
    print(f"ğŸ‘‰ è¾“å‡ºè·¯å¾„ï¼š{output_path}")
    print("ğŸ“‚ æ–‡ä»¶å¤¹å†…åŒ…å«ï¼š")
    
    if mode == "Extract":
        # Extractæ¨¡å¼è¾“å‡º
        mod_folder_name = os.path.basename(output_path)
        # ä»è¾“å‡ºè·¯å¾„ä¸­æå–modåç§°(å»æ‰æ—¶é—´æˆ³å‰ç¼€)
        mod_name = '_'.join(os.path.basename(output_path).split('_')[2:]) if len(os.path.basename(output_path).split('_')) >= 3 else os.path.basename(output_path)
        print(f"   1. {language}_mappings.json - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
        print(f"   2. {language}_mappings.yaml - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
        # ä»è¾“å‡ºè·¯å¾„ä¸­æå–æ—¶é—´æˆ³ï¼Œç”¨äºç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
        basename = os.path.basename(output_path)
        parts = basename.split('_')
        if len(parts) >= 2:
            timestamp = parts[0] + '_' + parts[1]
            print(f"   3. extract_{timestamp}_report.json - æµç¨‹æŠ¥å‘Š(å«æ£€æµ‹ç»“æœã€æ‰§è¡Œæ­¥éª¤ã€è€—æ—¶)")
            print(f"   4. mod_info.json - modä¿¡æ¯æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
        else:
            print(f"   3. mod_info.json - modä¿¡æ¯æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
        print("ğŸ’¡ å°è´´å£«ï¼š")
        print(f"   - è‹¥éœ€æ˜ å°„ï¼Œå¯å°† {language}_mappings.json æˆ– {language}_mappings.yaml + mod_info.jsonå¤åˆ¶åˆ°rule/{language}/{mod_name}")
        print(f"   - æŠ¥å‘Šä¸­è‹¥æ ‡ã€Œâš ï¸ã€ï¼Œä»£è¡¨jaråç¼–è¯‘æ—¶è·³è¿‡äº†æ— æ•ˆæ–‡ä»¶ï¼Œä¸å½±å“ç»“æœ")
    elif mode == "Extend":
        # Extendæ¨¡å¼è¾“å‡º
        mod_folder_name = os.path.basename(output_path)
        # ä»è¾“å‡ºè·¯å¾„ä¸­æå–modåç§°(å»æ‰æ—¶é—´æˆ³å‰ç¼€)
        mod_name = '_'.join(os.path.basename(output_path).split('_')[2:])
        print(f"   1. è¢«æ˜ å°„çš„Modæ–‡ä»¶å¤¹({mod_name}) - æ˜ å°„åçš„æºæ–‡ä»¶å¤¹")
        
        # æ ¹æ®è¾“å‡ºè·¯å¾„åˆ¤æ–­æ˜ å°„æ–¹å‘
        if "Extend_zh2en" in output_path:
            # ä¸­æ–‡æ˜ å°„åˆ°è‹±æ–‡
            print(f"   2. English_mappings.json - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)ç”±è¢«æ˜ å°„åçš„srcæ–‡ä»¶å¤¹æå–")
            print(f"   3. English_mappings.yaml - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)ç”±è¢«æ˜ å°„åçš„srcæ–‡ä»¶å¤¹æå–")
            # ä»è¾“å‡ºè·¯å¾„ä¸­æå–æ—¶é—´æˆ³
            timestamp = os.path.basename(output_path).split('_')[0] + '_' + os.path.basename(output_path).split('_')[1]
            print(f"   4. extend_{timestamp}_report.json - æµç¨‹æŠ¥å‘Š(å«æ£€æµ‹ç»“æœã€æ‰§è¡Œæ­¥éª¤ã€è€—æ—¶)")
            print(f"   5. mod_info.json - modä¿¡æ¯æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
            print("ğŸ’¡ å°è´´å£«ï¼š")
            print(f"   - è‹¥éœ€æ˜ å°„ï¼Œå¯å°† English_mappings.json æˆ– English_mappings.yaml + mod_info.jsonå¤åˆ¶åˆ°rule/English/{mod_name}")
            print(f"   - æŠ¥å‘Šä¸­è‹¥æ ‡ã€Œâš ï¸ã€ï¼Œä»£è¡¨jaråç¼–è¯‘æ—¶è·³è¿‡äº†æ— æ•ˆæ–‡ä»¶ï¼Œä¸å½±å“ç»“æœ")
        elif "Extend_en2zh" in output_path:
            # è‹±æ–‡æ˜ å°„åˆ°ä¸­æ–‡
            print(f"   2. Chinese_mappings.json - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)ç”±è¢«æ˜ å°„åçš„srcæ–‡ä»¶å¤¹æå–")
            print(f"   3. Chinese_mappings.yaml - å­—ç¬¦ä¸²æ˜ å°„è§„åˆ™æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)ç”±è¢«æ˜ å°„åçš„srcæ–‡ä»¶å¤¹æå–")
            # ä»è¾“å‡ºè·¯å¾„ä¸­æå–æ—¶é—´æˆ³
            timestamp = os.path.basename(output_path).split('_')[0] + '_' + os.path.basename(output_path).split('_')[1]
            print(f"   4. extend_{timestamp}_report.json - æµç¨‹æŠ¥å‘Š(å«æ£€æµ‹ç»“æœã€æ‰§è¡Œæ­¥éª¤ã€è€—æ—¶)")
            print(f"   5. mod_info.json - modä¿¡æ¯æ–‡ä»¶(å¯ç”¨äºExtendæ¨¡å¼)")
            print("ğŸ’¡ å°è´´å£«ï¼š")
            print(f"   - è‹¥éœ€æ˜ å°„ï¼Œå¯å°† Chinese_mappings.json æˆ– Chinese_mappings.yaml + mod_info.jsonå¤åˆ¶åˆ°rule/Chinese/{mod_name}")
            print(f"   - æŠ¥å‘Šä¸­è‹¥æ ‡ã€Œâš ï¸ã€ï¼Œä»£è¡¨jaråç¼–è¯‘æ—¶è·³è¿‡äº†æ— æ•ˆæ–‡ä»¶ï¼Œä¸å½±å“ç»“æœ")
    
    print("==========================================")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹
    global AUTO_OPEN_OUTPUT_FOLDER
    if AUTO_OPEN_OUTPUT_FOLDER:
        print("ğŸ”„ æ­£åœ¨è‡ªåŠ¨æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹...")
        from src.common.file_utils import open_directory
        open_directory(output_path)
        return
    else:
        # å¤„ç†ç”¨æˆ·è¾“å…¥
        print("è¾“å…¥ã€Œbackã€è¿”å›ä¸»èœå•ï¼Œè¾“å…¥ã€Œopenã€ç›´æ¥æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹ï¼š")
        while True:
            choice = input().strip().lower()
            if choice == "back":
                return
            elif choice == "open":
                from src.common.file_utils import open_directory
                open_directory(output_path)
                return
            else:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ã€Œbackã€æˆ–ã€Œopenã€ï¼š")


# æ·»åŠ æ˜ å°„è§„åˆ™ç®¡ç†å­æµç¨‹é€‰æ‹©å‡½æ•°
def select_localization_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©æ˜ å°„è§„åˆ™ç®¡ç†çš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹ç±»å‹
    """
    print("\n==========================================")
    print("        æ˜ å°„è§„åˆ™ç®¡ç† - æ“ä½œé€‰æ‹©")
    print("==========================================")
    print("è¯·é€‰æ‹©æ˜ å°„è§„åˆ™ç®¡ç†æ“ä½œï¼š")
    print("1. æå–æ˜ å°„è§„åˆ™")
    print("2. å¤„ç†æœªæ˜ å°„å†…å®¹")
    print("3. æ£€æµ‹å’Œè§£å†³å†²çª")
    print("4. è‡ªåŠ¨ç”Ÿæˆè§„åˆ™")
    print("5. ç®¡ç†æ˜ å°„è§„åˆ™")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("==========================================")

    while True:
        choice = input("è¾“å…¥æ•°å­—(0-5ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not choice:
            choice = "1"
        if choice == "0":
            return "return_to_previous"
        elif choice in ["1", "2", "3", "4", "5"]:
            sub_flows = {
                "1": "æå–æ˜ å°„è§„åˆ™",
                "2": "å¤„ç†æœªæ˜ å°„å†…å®¹",
                "3": "æ£€æµ‹å’Œè§£å†³å†²çª",
                "4": "è‡ªåŠ¨ç”Ÿæˆè§„åˆ™",
                "5": "ç®¡ç†æ˜ å°„è§„åˆ™"
            }
            return sub_flows[choice]
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(0-5)ï¼")

# æ·»åŠ æ˜ å°„è§„åˆ™ç®¡ç†æ‰§è¡Œå‡½æ•°
def run_localization_sub_flow(sub_flow: str, base_path: str) -> dict:
    """
    è¿è¡Œæ˜ å°„è§„åˆ™ç®¡ç†å­æµç¨‹

    Args:
        sub_flow: å­æµç¨‹ç±»å‹
        base_path: åŸºç¡€è·¯å¾„

    Returns:
        dict: å¤„ç†ç»“æœ
    """
    logger.info(f"æ‰§è¡Œæ˜ å°„è§„åˆ™ç®¡ç†å­æµç¨‹ï¼š{sub_flow}")
    
    result = {
        "status": "success",
        "data": {
            "total_count": 0,
            "success_count": 0,
            "fail_count": 0,
            "fail_reasons": []
        }
    }
    
    try:
        if sub_flow == "æå–æ˜ å°„è§„åˆ™":
            # è·å–ç”¨æˆ·è¾“å…¥
            source_dir = input("è¯·è¾“å…¥æºç›®å½•è·¯å¾„ï¼š").strip()
            output_file = input("è¯·è¾“å…¥è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            existing_rule = input("è¯·è¾“å…¥ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or None
            language = input("è¯·è¾“å…¥è¯­è¨€ç±»å‹ï¼ˆé»˜è®¤ï¼šEnglishï¼‰ï¼š").strip() or "English"
            
            # æ‰§è¡Œæå–æ˜ å°„è§„åˆ™
            result = extract_mapping_rules(
                source_dir=source_dir,
                existing_rule=existing_rule,
                output_file=output_file,
                language=language
            )
        elif sub_flow == "å¤„ç†æœªæ˜ å°„å†…å®¹":
            # è·å–ç”¨æˆ·è¾“å…¥
            rule_file = input("è¯·è¾“å…¥è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            report_file = input("è¯·è¾“å…¥æœªæ˜ å°„å†…å®¹æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or None
            list_unmapped = input("æ˜¯å¦åˆ—å‡ºæœªæ˜ å°„å†…å®¹ï¼Ÿ(y/nï¼Œé»˜è®¤n)ï¼š").strip().lower() == "y"
            mark_translated = input("æ˜¯å¦å°†æœªæ˜ å°„å†…å®¹æ ‡è®°ä¸ºå·²ç¿»è¯‘ï¼Ÿ(y/nï¼Œé»˜è®¤n)ï¼š").strip().lower() == "y"
            output_file = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or None
            
            # æ‰§è¡Œå¤„ç†æœªæ˜ å°„å†…å®¹
            result = process_unmapped_content(
                rule_file=rule_file,
                report_file=report_file,
                list_unmapped=list_unmapped,
                mark_translated=mark_translated,
                output_file=output_file
            )
        elif sub_flow == "æ£€æµ‹å’Œè§£å†³å†²çª":
            # è·å–ç”¨æˆ·è¾“å…¥
            rule_file = input("è¯·è¾“å…¥è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            report_file = input("è¯·è¾“å…¥å†²çªæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or None
            resolve = input("æ˜¯å¦è‡ªåŠ¨è§£å†³å†²çªï¼Ÿ(y/nï¼Œé»˜è®¤n)ï¼š").strip().lower() == "y"
            resolve_strategy = input("è¯·è¾“å…¥å†²çªè§£å†³ç­–ç•¥ï¼ˆlatest/oldestï¼Œé»˜è®¤latestï¼‰ï¼š").strip() or "latest"
            
            # æ‰§è¡Œæ£€æµ‹å’Œè§£å†³å†²çª
            result = detect_and_resolve_conflicts(
                rule_file=rule_file,
                generate_report=bool(report_file),
                report_file=report_file,
                resolve=resolve,
                resolve_strategy=resolve_strategy
            )
        elif sub_flow == "è‡ªåŠ¨ç”Ÿæˆè§„åˆ™":
            # è·å–ç”¨æˆ·è¾“å…¥
            chinese_src_dir = input("è¯·è¾“å…¥ä¸­æ–‡srcæ–‡ä»¶å¤¹è·¯å¾„ï¼š").strip()
            english_src_dir = input("è¯·è¾“å…¥è‹±æ–‡srcæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
            output_file = input("è¯·è¾“å…¥è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            mod_id = input("è¯·è¾“å…¥æ¨¡ç»„IDï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
            existing_rules = input("è¯·è¾“å…¥ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
            language = input("è¯·è¾“å…¥ä¸»è¦è¯­è¨€ç±»å‹ï¼ˆé»˜è®¤ï¼šEnglishï¼‰ï¼š").strip() or "English"
            
            # æ‰§è¡Œè‡ªåŠ¨ç”Ÿæˆè§„åˆ™
            result = auto_generate_rules(
                chinese_src_dir=chinese_src_dir,
                english_src_dir=english_src_dir,
                output_file=output_file,
                mod_id=mod_id,
                language=language,
                existing_rules=existing_rules
            )
        elif sub_flow == "ç®¡ç†æ˜ å°„è§„åˆ™":
            # æ‰§è¡Œæ˜ å°„è§„åˆ™ç®¡ç†
            result = manage_rules()
        elif sub_flow == "return_to_previous":
            return {"status": "success", "message": "è¿”å›ä¸Šä¸€çº§èœå•"}
        
        return result
    except Exception as e:
        logger.exception(f"æ‰§è¡Œæ˜ å°„è§„åˆ™ç®¡ç†å­æµç¨‹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        result['status'] = 'fail'
        result['data']['fail_count'] = 1
        result['data']['fail_reasons'].append(str(e))
        result['data']['total_count'] = 1
        return result

# æ·»åŠ å®Œæ•´å·¥ä½œæµå­æµç¨‹é€‰æ‹©å‡½æ•°
def select_workflow_sub_flow() -> str:
    """
    è®©ç”¨æˆ·é€‰æ‹©å®Œæ•´å·¥ä½œæµçš„å­æµç¨‹

    Returns:
        str: é€‰æ‹©çš„å­æµç¨‹ç±»å‹
    """
    print("\n==========================================")
    print("        å®Œæ•´å·¥ä½œæµ - æ“ä½œé€‰æ‹©")
    print("==========================================")
    print("è¯·é€‰æ‹©å®Œæ•´å·¥ä½œæµæ“ä½œï¼š")
    print("1. ç”Ÿæˆç¿»è¯‘è§„åˆ™")
    print("2. æ›´æ–°ç¿»è¯‘è§„åˆ™")
    print("3. è¿è¡Œå®Œæ•´å·¥ä½œæµ")
    print("0. è¿”å›ä¸Šä¸€çº§èœå•")
    print("==========================================")

    while True:
        choice = input("è¾“å…¥æ•°å­—(0-3ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1)ï¼š").strip()
        if not choice:
            choice = "1"
        if choice == "0":
            return "return_to_previous"
        elif choice in ["1", "2", "3"]:
            sub_flows = {
                "1": "ç”Ÿæˆç¿»è¯‘è§„åˆ™",
                "2": "æ›´æ–°ç¿»è¯‘è§„åˆ™",
                "3": "è¿è¡Œå®Œæ•´å·¥ä½œæµ"
            }
            return sub_flows[choice]
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—(0-3)ï¼")

# æ·»åŠ å®Œæ•´å·¥ä½œæµæ‰§è¡Œå‡½æ•°
def run_workflow_sub_flow(sub_flow: str, base_path: str) -> dict:
    """
    è¿è¡Œå®Œæ•´å·¥ä½œæµå­æµç¨‹

    Args:
        sub_flow: å­æµç¨‹ç±»å‹
        base_path: åŸºç¡€è·¯å¾„

    Returns:
        dict: å¤„ç†ç»“æœ
    """
    logger.info(f"æ‰§è¡Œå®Œæ•´å·¥ä½œæµå­æµç¨‹ï¼š{sub_flow}")
    
    result = {
        "status": "success",
        "data": {
            "total_count": 0,
            "success_count": 0,
            "fail_count": 0,
            "fail_reasons": []
        }
    }
    
    try:
        if sub_flow == "ç”Ÿæˆç¿»è¯‘è§„åˆ™":
            # è·å–ç”¨æˆ·è¾“å…¥
            english_file = input("è¯·è¾“å…¥è‹±æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
            chinese_file = input("è¯·è¾“å…¥ä¸­æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
            output_file = input("è¯·è¾“å…¥è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            mod_id = input("è¯·è¾“å…¥æ¨¡ç»„IDï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
            
            # æ‰§è¡Œç”Ÿæˆç¿»è¯‘è§„åˆ™
            result = generate_translation_rules(
                english_file=english_file,
                chinese_file=chinese_file,
                output_file=output_file,
                mod_id=mod_id
            )
        elif sub_flow == "æ›´æ–°ç¿»è¯‘è§„åˆ™":
            # è·å–ç”¨æˆ·è¾“å…¥
            existing_rules_file = input("è¯·è¾“å…¥ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            new_english_file = input("è¯·è¾“å…¥æ–°çš„è‹±æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
            new_chinese_file = input("è¯·è¾“å…¥æ–°çš„ä¸­æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
            output_file = input("è¯·è¾“å…¥è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„ï¼š").strip()
            mod_id = input("è¯·è¾“å…¥æ¨¡ç»„IDï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
            
            # æ‰§è¡Œæ›´æ–°ç¿»è¯‘è§„åˆ™
            result = update_translation_rules(
                existing_rules_file=existing_rules_file,
                new_english_file=new_english_file,
                new_chinese_file=new_chinese_file,
                output_file=output_file,
                mod_id=mod_id
            )
        elif sub_flow == "è¿è¡Œå®Œæ•´å·¥ä½œæµ":
            # è‡ªåŠ¨é€‰æ‹©modæ–‡ä»¶å¤¹
            print("[INFO] æ­£åœ¨è‡ªåŠ¨è¯†åˆ«å¯ç”¨çš„modæ–‡ä»¶å¤¹...")
            source_dir = select_mod_folder()
            
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å–æ¶ˆé€‰æ‹©
            if not source_dir:
                return {"status": "success", "message": "è¿”å›ä¸Šä¸€çº§èœå•"}
            
            # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºç›®å½•è·¯å¾„
            mod_name = os.path.basename(source_dir)
            output_dir = os.path.join(get_directory("output"), f"Workflow_{mod_name}")
            print(f"[INFO] è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºç›®å½•ï¼š{output_dir}")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨åŒè¯­srcæ–‡ä»¶å¤¹
            use_bilingual_src = input("æ˜¯å¦ä½¿ç”¨åŒè¯­srcæ–‡ä»¶å¤¹è‡ªåŠ¨ç”Ÿæˆè§„åˆ™ï¼Ÿ(y/nï¼Œé»˜è®¤n)ï¼š").strip().lower() == "y"
            
            if use_bilingual_src:
                # è‡ªåŠ¨è·å–åŒè¯­srcæ–‡ä»¶å¤¹è·¯å¾„
                # å‡è®¾åŒè¯­srcæ–‡ä»¶å¤¹ä½äºsourceç›®å½•ä¸‹çš„Englishå’ŒChineseå­æ–‡ä»¶å¤¹ä¸­
                source_root = os.path.dirname(os.path.dirname(source_dir))
                bilingual_src_dir = source_root
                print(f"[INFO] è‡ªåŠ¨è¯†åˆ«åŒè¯­srcæ–‡ä»¶å¤¹ï¼š{bilingual_src_dir}")
                
                mod_id = input("è¯·è¾“å…¥æ¨¡ç»„IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨modåç§°ï¼‰ï¼š").strip() or mod_name
                existing_rules = input("è¯·è¾“å…¥ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
                
                # æ‰§è¡Œè¿è¡Œå®Œæ•´å·¥ä½œæµï¼Œä½¿ç”¨åŒè¯­srcæ–‡ä»¶å¤¹
                result = run_complete_workflow(
                    source_dir=source_dir,
                    output_dir=output_dir,
                    bilingual_src_dir=bilingual_src_dir,
                    mod_id=mod_id,
                    existing_rules=existing_rules
                )
            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ï¼Œéœ€è¦è‹±æ–‡å’Œä¸­æ–‡æ˜ å°„æ–‡ä»¶
                english_file = input("è¯·è¾“å…¥è‹±æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
                chinese_file = input("è¯·è¾“å…¥ä¸­æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼š").strip()
                mod_id = input("è¯·è¾“å…¥æ¨¡ç»„IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨modåç§°ï¼‰ï¼š").strip() or mod_name
                existing_rules = input("è¯·è¾“å…¥ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼š").strip() or ""
                
                # æ‰§è¡Œè¿è¡Œå®Œæ•´å·¥ä½œæµ
                result = run_complete_workflow(
                    source_dir=source_dir,
                    output_dir=output_dir,
                    english_file=english_file,
                    chinese_file=chinese_file,
                    mod_id=mod_id,
                    existing_rules=existing_rules
                )
        elif sub_flow == "return_to_previous":
            return {"status": "success", "message": "è¿”å›ä¸Šä¸€çº§èœå•"}
        
        return result
    except Exception as e:
        logger.exception(f"æ‰§è¡Œå®Œæ•´å·¥ä½œæµå­æµç¨‹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        result['status'] = 'fail'
        result['data']['fail_count'] = 1
        result['data']['fail_reasons'].append(str(e))
        result['data']['total_count'] = 1
        return result

# ä»é…ç½®ç®¡ç†å™¨ä¸­è·å–è®¾ç½®
from src.common.config_utils import get_setting, set_setting

# å…¨å±€å˜é‡ï¼šæ˜¯å¦æ˜¾ç¤ºæ¬¢è¿å¼•å¯¼
SHOW_WELCOME_GUIDE = get_setting("show_welcome_guide")

# å…¨å±€å˜é‡ï¼šæ˜¯å¦è‡ªåŠ¨æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹
AUTO_OPEN_OUTPUT_FOLDER = get_setting("auto_open_output_folder")

# ç§»é™¤é«˜çº§æ¨¡å¼é…ç½®ï¼Œç®€åŒ–ä»£ç 
ADVANCED_MODE_ENABLED = False  # ç¦ç”¨é«˜çº§æ¨¡å¼
MAIN_LANGUAGE = "å…¨éƒ¨"  # é»˜è®¤å€¼
PROCESS_GRANULARITY_ENABLED = False  # é»˜è®¤å€¼
PRECHECK_MECHANISM_ENABLED = False  # é»˜è®¤å€¼


# ä¿®æ”¹mainå‡½æ•°ï¼Œç§»é™¤å†—ä½™ä»£ç ï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°
def main():
    """
    ä¸»å‡½æ•°
    """
    logger.info("==========================================")
    logger.info("               ModLocale")
    logger.info("==========================================")
    logger.info("å·¥å…·å¯åŠ¨ï¼Œå¼€å§‹è§£æå‘½ä»¤è¡Œå‚æ•°")
    
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        if not load_config():
            print("[ERROR] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥")
            return
        
        # éªŒè¯ç›®å½•ç»“æ„
        if not validate_directories():
            print("[ERROR] éªŒè¯ç›®å½•ç»“æ„å¤±è´¥")
            return
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ˜¾ç¤ºæ¬¢è¿å¼•å¯¼
        if SHOW_WELCOME_GUIDE:
            logger.info("å‰ç½®æ£€æŸ¥å·²å¼€å¯ï¼Œæ˜¾ç¤ºæ¬¢è¿å¼•å¯¼")
            show_welcome_guide()
        else:
            logger.info("å‰ç½®æ£€æŸ¥å·²é»˜è®¤å…³é—­ï¼Œç›´æ¥è¿›å…¥ä¸»èœå•")
        
        # æ£€æŸ¥é¡¹ç›®ç»“æ„
        if not check_project_structure():
            return
        
        # åˆå§‹åŒ–init_modeï¼Œæ„å»ºmodæ˜ å°„å…³ç³»
        try:
            from src.init_mode import run_init_tasks
            from src.common.config_utils import get_directory
            mod_root = get_directory("mod_root")
            if mod_root:
                init_result = run_init_tasks(mod_root)
                logger.info(f"init_modeåˆå§‹åŒ–å®Œæˆï¼ŒçŠ¶æ€: {init_result['status']}")
                if init_result['status'] == 'fail':
                    print(f"[WARN]  init_modeåˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½å½±å“åç»­æ“ä½œ: {init_result['data']['fail_reasons']}")
        except Exception as e:
            logger.exception(f"åˆå§‹åŒ–init_modeæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            print(f"[WARN]  åˆå§‹åŒ–init_modeæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(
            description="ModLocale ä¸»å…¥å£ï¼Œæä¾›Extractã€Extendã€Decompileæ¨¡å¼ï¼Œä»¥åŠæ˜ å°„è§„åˆ™ç®¡ç†å’Œå®Œæ•´å·¥ä½œæµ",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""ç¤ºä¾‹ç”¨æ³•ï¼š

=== Extractæ¨¡å¼ç¤ºä¾‹ ===
python main.py extract "è‹±æ–‡æå–æµç¨‹"
python main.py extract -h

=== Extendæ¨¡å¼ç¤ºä¾‹ ===
python main.py extend "å·²æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹"
python main.py extend -h

=== Decompileæ¨¡å¼ç¤ºä¾‹ ===
python main.py decompile "åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶"
python main.py decompile "åç¼–è¯‘ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶"
python main.py decompile "æå–å•ä¸ªJARæ–‡ä»¶å†…å®¹"
python main.py decompile "æå–ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶å†…å®¹"
python main.py decompile -h

=== æ˜ å°„è§„åˆ™ç®¡ç†ç¤ºä¾‹ ===
python main.py localization extract --source-dir ./src --output-file ./rules.yaml
python main.py localization generate-rules --english-file ./en.yaml --chinese-file ./zh.yaml --output-file ./rules.yaml
python main.py localization -h

=== å®Œæ•´å·¥ä½œæµç¤ºä¾‹ ===
python main.py workflow workflow --english-file ./en.yaml --chinese-file ./zh.yaml --source-dir ./src --output-dir ./output
python main.py workflow generate-rules --english-file ./en.yaml --chinese-file ./zh.yaml --output-file ./rules.yaml
python main.py workflow -h

=== æµ‹è¯•æ¨¡å¼ç¤ºä¾‹ ===
python main.py --test-mode "1,1,1"  # æµ‹è¯•Extractæ¨¡å¼-ç®€æ´æ¨¡å¼-æå–è‹±æ–‡
python main.py --test-mode "1,2,1"  # æµ‹è¯•Extractæ¨¡å¼-å®Œæ•´æ¨¡å¼-å·²æœ‰è‹±æ–‡src
python main.py --test-mode "2,1,1"  # æµ‹è¯•Extendæ¨¡å¼-ç®€æ´æ¨¡å¼-ä¸­æ–‡æ˜ å°„åˆ°è‹±æ–‡
python main.py --test-mode "4,1"  # æµ‹è¯•Decompileæ¨¡å¼-åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶
        """,
        )
        
        # æ·»åŠ æµ‹è¯•æ¨¡å¼å‚æ•°
        parser.add_argument(
            "--test-mode",
            type=str,
            help="æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨é€—å·åˆ†éš”çš„æ•°å­—åºåˆ—æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥ï¼Œä¾‹å¦‚ï¼š'1,1,1'",
            default=None
        )

        # åˆ›å»ºå­å‘½ä»¤è§£æå™¨
        subparsers = parser.add_subparsers(dest="mode", help="è¦ä½¿ç”¨çš„æ¨¡å¼", required=False)

        # Extractæ¨¡å¼å­å‘½ä»¤
        extract_parser = subparsers.add_parser(
            "extract",
            help="æ‰§è¡ŒExtractæ¨¡å¼ï¼Œç”¨äºæå–å­—ç¬¦ä¸²",
            description="Extractæ¨¡å¼ç”¨äºä»srcç›®å½•æå–å­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œç¿»è¯‘\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  ç®€åŒ–æ¨¡å¼(äº¤äº’å¼)ï¼šä»…æ˜¾ç¤ºæ ¸å¿ƒé€‰é¡¹ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œåˆé€‚çš„å­æµç¨‹\n" \
            "  é«˜çº§æ¨¡å¼(äº¤äº’å¼)ï¼šæ˜¾ç¤ºå®Œæ•´çš„å››ç§å­æµç¨‹ï¼Œå…è®¸æ‰‹åŠ¨é€‰æ‹©\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå­æµç¨‹ç±»å‹",
        )
        extract_parser.add_argument(
            "sub_flow",
            nargs="?",
            help="å­æµç¨‹ç±»å‹ï¼Œå¯é€‰å€¼ï¼š\n"  \
            "  ç®€åŒ–æ¨¡å¼å¯ç”¨ï¼šè‹±æ–‡æå–æµç¨‹, ä¸­æ–‡æå–æµç¨‹\n"  \
            "  é«˜çº§æ¨¡å¼å¯ç”¨ï¼šå·²æœ‰è‹±æ–‡srcæ–‡ä»¶å¤¹æå–æµç¨‹, æ²¡æœ‰è‹±æ–‡srcæ–‡ä»¶å¤¹æå–æµç¨‹, å·²æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æå–æµç¨‹, æ²¡æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æå–æµç¨‹",
        )

        # Extendæ¨¡å¼å­å‘½ä»¤
        extend_parser = subparsers.add_parser(
            "extend",
            help="æ‰§è¡ŒExtendæ¨¡å¼ï¼Œç”¨äºæ˜ å°„å­—ç¬¦ä¸²",
            description="Extendæ¨¡å¼ç”¨äºä½¿ç”¨æ˜ å°„è§„åˆ™æ˜ å°„å­—ç¬¦ä¸²ï¼Œå®ç°Chineseæ˜ å°„English",
        )
        extend_parser.add_argument(
            "sub_flow",
            nargs="?",
            help="å­æµç¨‹ç±»å‹ï¼Œå¯é€‰å€¼ï¼š\n"  \
            "  å·²æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹\n"  \
            "  æ²¡æœ‰ä¸­æ–‡srcæ–‡ä»¶å¤¹æ˜ å°„æµç¨‹\n"  \
            "  å·²æœ‰ä¸­æ–‡æ˜ å°„è§„åˆ™æ–‡ä»¶æµç¨‹",
        )
        
        # Decompileæ¨¡å¼å­å‘½ä»¤
        decompile_parser = subparsers.add_parser(
            "decompile",
            help="æ‰§è¡ŒDecompileæ¨¡å¼ï¼Œç”¨äºåç¼–è¯‘æˆ–æå–JARæ–‡ä»¶",
            description="Decompileæ¨¡å¼ç”¨äºåç¼–è¯‘æˆ–æå–JARæ–‡ä»¶\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  ç®€åŒ–æ¨¡å¼(äº¤äº’å¼)ï¼šä»…æ˜¾ç¤ºæ ¸å¿ƒé€‰é¡¹ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œåˆé€‚çš„å­æµç¨‹\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå­æµç¨‹ç±»å‹",
        )
        decompile_parser.add_argument(
            "sub_flow",
            nargs="?",
            help="å­æµç¨‹ç±»å‹ï¼Œå¯é€‰å€¼ï¼š\n"  \
            "  åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶\n"  \
            "  åç¼–è¯‘ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶\n"  \
            "  æå–å•ä¸ªJARæ–‡ä»¶å†…å®¹\n"  \
            "  æå–ç›®å½•ä¸­æ‰€æœ‰JARæ–‡ä»¶å†…å®¹",
        )
        
        # æ˜ å°„è§„åˆ™ç®¡ç†å­å‘½ä»¤
        localization_parser = subparsers.add_parser(
            "localization",
            help="æ‰§è¡Œæ˜ å°„è§„åˆ™ç®¡ç†ï¼ŒåŒ…æ‹¬æå–ã€å¤„ç†æœªæ˜ å°„å†…å®¹ã€å†²çªæ£€æµ‹ç­‰",
            description="æ˜ å°„è§„åˆ™ç®¡ç†ï¼Œç”¨äºå¤„ç†ç¿»è¯‘è§„åˆ™çš„æå–ã€æ›´æ–°ã€å†²çªæ£€æµ‹å’Œè§£å†³\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå­å‘½ä»¤å’Œå‚æ•°",
            epilog="ç¤ºä¾‹ç”¨æ³•ï¼š\n" \
            "python main.py localization extract --source-dir ./src --output-file mappings.yaml\n" \
            "python main.py localization conflict --rule-file mappings.yaml --report conflict_report.txt",
        )
        localization_parser.add_argument(
            "subcommand",
            nargs="?",
            help="æœ¬åœ°åŒ–å­å‘½ä»¤ï¼Œå¯é€‰å€¼ï¼šextract, process-unmapped, conflict, generate-rules, update-rules",
        )
        localization_parser.add_argument(
            "args",
            nargs=argparse.REMAINDER,
            help="æœ¬åœ°åŒ–å­å‘½ä»¤çš„å‚æ•°",
        )
        
        # å®Œæ•´å·¥ä½œæµå­å‘½ä»¤
        workflow_parser = subparsers.add_parser(
            "workflow",
            help="æ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ŒåŒ…æ‹¬ç”Ÿæˆè§„åˆ™ã€å†²çªæ£€æµ‹ã€ç¿»è¯‘å›å†™ç­‰",
            description="å®Œæ•´å·¥ä½œæµï¼Œç”¨äºæ‰§è¡Œä»åŒè¯­æ•°æ®åˆ°ç¿»è¯‘å›å†™çš„å®Œæ•´æµç¨‹\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå­å‘½ä»¤å’Œå‚æ•°",
            epilog="ç¤ºä¾‹ç”¨æ³•ï¼š\n" \
            "python main.py workflow generate-rules --english-file en.yaml --chinese-file zh.yaml --output-file rules.yaml\n" \
            "python main.py workflow workflow --english-file en.yaml --chinese-file zh.yaml --source-dir ./src --output-dir ./output",
        )
        workflow_parser.add_argument(
            "subcommand",
            nargs="?",
            help="å·¥ä½œæµå­å‘½ä»¤ï¼Œå¯é€‰å€¼ï¼šgenerate-rules, update-rules, workflow",
        )
        workflow_parser.add_argument(
            "args",
            nargs=argparse.REMAINDER,
            help="å·¥ä½œæµå­å‘½ä»¤çš„å‚æ•°",
        )
        
        # Bootstrapå‘½ä»¤ï¼Œç”¨äºä»EN+ZHä¸¤å¥—srcç”ŸæˆRich rules
        bootstrap_parser = subparsers.add_parser(
            "bootstrap",
            help="ä»EN+ZHä¸¤å¥—srcç”ŸæˆRich rules",
            description="ä»EN+ZHä¸¤å¥—srcç›´æ¥ç”Ÿæˆå¯å›å†™çš„Rich rulesæ–‡ä»¶\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå‚æ•°",
            epilog="ç¤ºä¾‹ç”¨æ³•ï¼š\n" \
            "python main.py bootstrap --en-src ./source/English/src --zh-src ./source/Chinese/src --mod-id my-mod --out ./rules/rich_rules.yaml",
        )
        bootstrap_parser.add_argument(
            "--en-src",
            required=True,
            help="è‹±æ–‡æºç ç›®å½•è·¯å¾„",
        )
        bootstrap_parser.add_argument(
            "--zh-src",
            required=True,
            help="ä¸­æ–‡æºç ç›®å½•è·¯å¾„",
        )
        bootstrap_parser.add_argument(
            "--mod-id",
            required=True,
            help="æ¨¡ç»„ID",
        )
        bootstrap_parser.add_argument(
            "--out",
            required=True,
            help="è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„",
        )
        bootstrap_parser.add_argument(
            "--use-cache",
            action="store_true",
            help="æ˜¯å¦ä½¿ç”¨ç¼“å­˜æœºåˆ¶",
            default=True,
        )
        
        # Ruleså‘½ä»¤ï¼Œç”¨äºè§„åˆ™ç®¡ç†
        rules_parser = subparsers.add_parser(
            "rules",
            help="è§„åˆ™ç®¡ç†å­å‘½ä»¤",
            description="è§„åˆ™ç®¡ç†å‘½ä»¤ï¼Œæ”¯æŒè§„åˆ™çš„åˆ—è¡¨ã€æ˜¾ç¤ºã€è®¾ç½®ã€åˆ é™¤ã€éªŒè¯ã€å¯¼å…¥å’Œå¯¼å‡º\n\n" \
            "æ“ä½œæ¨¡å¼ï¼š\n" \
            "  å‘½ä»¤è¡Œæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šå­å‘½ä»¤å’Œå‚æ•°",
            epilog="ç¤ºä¾‹ç”¨æ³•ï¼š\n" \
            "python main.py rules list --rules-file ./rules/rich_rules.yaml\n" \
            "python main.py rules show --rules-file ./rules/rich_rules.yaml --rule-id <rule-id>\n" \
            "python main.py rules validate --rules-file ./rules/rich_rules.yaml\n" \
            "python main.py rules export --rules-file ./rules/rich_rules.yaml --out ./simple_mapping.yaml --format simple",
        )
        rules_parser.add_argument(
            "subcommand",
            help="è§„åˆ™ç®¡ç†å­å‘½ä»¤ï¼Œå¯é€‰å€¼ï¼šlist, show, set, delete, validate, import, export",
            choices=["list", "show", "set", "delete", "validate", "import", "export"]
        )
        rules_parser.add_argument(
            "args",
            nargs=argparse.REMAINDER,
            help="è§„åˆ™ç®¡ç†å­å‘½ä»¤çš„å‚æ•°",
        )

        # è§£æå‘½ä»¤è¡Œå‚æ•°
        args = parser.parse_args()
        
        # å¤„ç†æµ‹è¯•æ¨¡å¼
        test_mode = args.test_mode
        if test_mode:
            # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥çš„å…¨å±€å˜é‡
            global __test_input_sequence
            global __test_input_index
            __test_input_sequence = test_mode.split(',')
            __test_input_index = 0
            
            # æ›¿æ¢inputå‡½æ•°ï¼Œæ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
            import builtins
            original_input = builtins.input
            
            def mock_input(prompt):
                global __test_input_index
                if __test_input_index < len(__test_input_sequence):
                    user_input = __test_input_sequence[__test_input_index]
                    __test_input_index += 1
                    print(f"{prompt}{user_input}")
                    return user_input
                else:
                    print(f"{prompt}")
                    return "1"  # é»˜è®¤å€¼
            
            builtins.input = mock_input
            logger.info(f"æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ï¼Œè¾“å…¥åºåˆ—ï¼š{test_mode}")
        
        # æ£€æŸ¥sub_flowæ˜¯å¦å­˜åœ¨
        sub_flow_value = getattr(args, 'sub_flow', None)
        logger.info(f"å‘½ä»¤è¡Œå‚æ•°è§£æå®Œæˆï¼šmode={args.mode}, sub_flow={sub_flow_value}")

        result = None
        # æ‰§è¡Œç›¸åº”çš„æ¨¡å¼
        if args.mode == "extract":
            logger.info("é€‰æ‹©Extractæ¨¡å¼")
            if args.sub_flow:
                # ç›´æ¥æ‰§è¡ŒæŒ‡å®šçš„å­æµç¨‹
                logger.info(f"ç›´æ¥æ‰§è¡ŒExtractå­æµç¨‹ï¼š{args.sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtract")
                print(f"æµç¨‹ï¼š{args.sub_flow}")
                print("==========================================")
                result = run_extract_sub_flow(args.sub_flow, None)
            else:
                # è®©ç”¨æˆ·é€‰æ‹©å­æµç¨‹
                logger.info("ç”¨æˆ·æœªæŒ‡å®šå­æµç¨‹ï¼Œæ˜¾ç¤ºExtractå­æµç¨‹é€‰æ‹©èœå•")
                sub_flow = select_extract_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Extractå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtract")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_extract_sub_flow(sub_flow, None)
        elif args.mode == "extend":
            logger.info("é€‰æ‹©Extendæ¨¡å¼")
            if args.sub_flow:
                # ç›´æ¥æ‰§è¡ŒæŒ‡å®šçš„å­æµç¨‹
                logger.info(f"ç›´æ¥æ‰§è¡ŒExtendå­æµç¨‹ï¼š{args.sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtend")
                print(f"æµç¨‹ï¼š{args.sub_flow}")
                print("==========================================")
                result = run_extend_sub_flow(args.sub_flow, None)
            else:
                # è®©ç”¨æˆ·é€‰æ‹©å­æµç¨‹
                logger.info("ç”¨æˆ·æœªæŒ‡å®šå­æµç¨‹ï¼Œæ˜¾ç¤ºExtendå­æµç¨‹é€‰æ‹©èœå•")
                sub_flow = select_extend_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Extendå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtend")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_extend_sub_flow(sub_flow, None)
        elif args.mode == "decompile":
            logger.info("é€‰æ‹©Decompileæ¨¡å¼")
            if args.sub_flow:
                # ç›´æ¥æ‰§è¡ŒæŒ‡å®šçš„å­æµç¨‹
                logger.info(f"ç›´æ¥æ‰§è¡ŒDecompileå­æµç¨‹ï¼š{args.sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šDecompile")
                print(f"æµç¨‹ï¼š{args.sub_flow}")
                print("==========================================")
                result = run_decompile_sub_flow(args.sub_flow, None)
            else:
                # è®©ç”¨æˆ·é€‰æ‹©å­æµç¨‹
                logger.info("ç”¨æˆ·æœªæŒ‡å®šå­æµç¨‹ï¼Œæ˜¾ç¤ºDecompileå­æµç¨‹é€‰æ‹©èœå•")
                sub_flow = select_decompile_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Decompileå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šDecompile")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_decompile_sub_flow(sub_flow, None)
        elif args.mode == "localization":
            logger.info("é€‰æ‹©æ˜ å°„è§„åˆ™ç®¡ç†æ¨¡å¼")
            print(f"\næ‰§è¡Œé…ç½®ï¼š")
            print(f"æ¨¡å¼ï¼šæ˜ å°„è§„åˆ™ç®¡ç†")
            print(f"å­å‘½ä»¤ï¼š{args.subcommand}")
            print(f"å‚æ•°ï¼š{' '.join(args.args)}")
            print("==========================================")
            
            # å¤„ç†æ˜ å°„è§„åˆ™ç®¡ç†å‘½ä»¤
            result = None
            try:
                if args.subcommand == "extract":
                    # è§£æextractå­å‘½ä»¤å‚æ•°
                    extract_parser = argparse.ArgumentParser(prog="localization extract")
                    extract_parser.add_argument("--source-dir", required=True, help="æºç›®å½•è·¯å¾„")
                    extract_parser.add_argument("--processed-dir", help="å·²å¤„ç†æ–‡ä»¶å¤¹è·¯å¾„")
                    extract_parser.add_argument("--existing-rule", help="ç°æœ‰è§„åˆ™æ–‡ä»¶è·¯å¾„")
                    extract_parser.add_argument("--output-file", required=True, help="è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„")
                    extract_parser.add_argument("--language", default="English", help="è¯­è¨€ç±»å‹")
                    extract_args = extract_parser.parse_args(args.args)
                    
                    result = extract_mapping_rules(
                        source_dir=extract_args.source_dir,
                        processed_dir=extract_args.processed_dir,
                        existing_rule=extract_args.existing_rule,
                        output_file=extract_args.output_file,
                        language=extract_args.language
                    )
                    
                elif args.subcommand == "process-unmapped":
                    # è§£æprocess-unmappedå­å‘½ä»¤å‚æ•°
                    process_parser = argparse.ArgumentParser(prog="localization process-unmapped")
                    process_parser.add_argument("--rule-file", required=True, help="è§„åˆ™æ–‡ä»¶è·¯å¾„")
                    process_parser.add_argument("--unmapped-file", required=True, help="æœªæ˜ å°„å†…å®¹æ–‡ä»¶è·¯å¾„")
                    process_parser.add_argument("--output-file", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
                    process_parser.add_argument("--language", default="English", help="è¯­è¨€ç±»å‹")
                    process_args = process_parser.parse_args(args.args)
                    
                    result = process_unmapped_content(
                        rule_file=process_args.rule_file,
                        unmapped_file=process_args.unmapped_file,
                        output_file=process_args.output_file,
                        language=process_args.language
                    )
                    
                elif args.subcommand == "conflict":
                    # è§£æconflictå­å‘½ä»¤å‚æ•°
                    conflict_parser = argparse.ArgumentParser(prog="localization conflict")
                    conflict_parser.add_argument("--rule-file", required=True, help="è§„åˆ™æ–‡ä»¶è·¯å¾„")
                    conflict_parser.add_argument("--report", help="å†²çªæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
                    conflict_args = conflict_parser.parse_args(args.args)
                    
                    result = detect_and_resolve_conflicts(
                        rule_file=conflict_args.rule_file,
                        report_file=conflict_args.report
                    )
                    
                else:
                    print(f"[ERROR] æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}")
                    logger.error(f"æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}")
                    result = {"status": "error", "message": f"æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}"}
                    
            except SystemExit:
                # å¤„ç†argparseçš„é€€å‡º
                result = {"status": "error", "message": "å‚æ•°è§£æå¤±è´¥"}
            except Exception as e:
                logger.exception(f"æ˜ å°„è§„åˆ™ç®¡ç†æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                print(f"[ERROR] æ˜ å°„è§„åˆ™ç®¡ç†æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                result = {"status": "error", "message": str(e)}
        elif args.mode == "workflow":
            logger.info("é€‰æ‹©å®Œæ•´å·¥ä½œæµæ¨¡å¼")
            print(f"\næ‰§è¡Œé…ç½®ï¼š")
            print(f"æ¨¡å¼ï¼šå®Œæ•´å·¥ä½œæµ")
            print(f"å­å‘½ä»¤ï¼š{args.subcommand}")
            print(f"å‚æ•°ï¼š{' '.join(args.args)}")
            print("==========================================")
            
            # å¤„ç†å®Œæ•´å·¥ä½œæµå‘½ä»¤
            result = None
            try:
                if args.subcommand == "generate-rules":
                    # è§£ægenerate-ruleså­å‘½ä»¤å‚æ•°
                    generate_parser = argparse.ArgumentParser(prog="workflow generate-rules")
                    generate_parser.add_argument("--english-file", required=True, help="è‹±æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„")
                    generate_parser.add_argument("--chinese-file", required=True, help="ä¸­æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„")
                    generate_parser.add_argument("--output-file", required=True, help="è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„")
                    generate_parser.add_argument("--mod-id", default="", help="æ¨¡ç»„ID")
                    generate_args = generate_parser.parse_args(args.args)
                    
                    result = generate_translation_rules(
                        english_file=generate_args.english_file,
                        chinese_file=generate_args.chinese_file,
                        output_file=generate_args.output_file,
                        mod_id=generate_args.mod_id
                    )
                    
                elif args.subcommand == "update-rules":
                    # è§£æupdate-ruleså­å‘½ä»¤å‚æ•°
                    update_parser = argparse.ArgumentParser(prog="workflow update-rules")
                    update_parser.add_argument("--rule-file", required=True, help="è§„åˆ™æ–‡ä»¶è·¯å¾„")
                    update_parser.add_argument("--new-content", required=True, help="æ–°å†…å®¹æ–‡ä»¶è·¯å¾„")
                    update_parser.add_argument("--output-file", required=True, help="è¾“å‡ºè§„åˆ™æ–‡ä»¶è·¯å¾„")
                    update_parser.add_argument("--language", default="English", help="è¯­è¨€ç±»å‹")
                    update_args = update_parser.parse_args(args.args)
                    
                    result = update_translation_rules(
                        rule_file=update_args.rule_file,
                        new_content=update_args.new_content,
                        output_file=update_args.output_file,
                        language=update_args.language
                    )
                    
                elif args.subcommand == "workflow":
                    # è§£æworkflowå­å‘½ä»¤å‚æ•°
                    workflow_parser = argparse.ArgumentParser(prog="workflow workflow")
                    workflow_parser.add_argument("--english-file", required=True, help="è‹±æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„")
                    workflow_parser.add_argument("--chinese-file", required=True, help="ä¸­æ–‡æ˜ å°„æ–‡ä»¶è·¯å¾„")
                    workflow_parser.add_argument("--source-dir", required=True, help="æºç›®å½•è·¯å¾„")
                    workflow_parser.add_argument("--output-dir", required=True, help="è¾“å‡ºç›®å½•è·¯å¾„")
                    workflow_parser.add_argument("--mod-id", default="", help="æ¨¡ç»„ID")
                    workflow_parser.add_argument("--language", default="English", help="è¯­è¨€ç±»å‹")
                    workflow_args = workflow_parser.parse_args(args.args)
                    
                    result = run_complete_workflow(
                        english_file=workflow_args.english_file,
                        chinese_file=workflow_args.chinese_file,
                        source_dir=workflow_args.source_dir,
                        output_dir=workflow_args.output_dir,
                        mod_id=workflow_args.mod_id,
                        language=workflow_args.language
                    )
                    
                else:
                    print(f"[ERROR] æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}")
                    logger.error(f"æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}")
                    result = {"status": "error", "message": f"æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}"}
                    
            except SystemExit:
                # å¤„ç†argparseçš„é€€å‡º
                result = {"status": "error", "message": "å‚æ•°è§£æå¤±è´¥"}
            except Exception as e:
                logger.exception(f"å®Œæ•´å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                print(f"[ERROR] å®Œæ•´å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                result = {"status": "error", "message": str(e)}
        elif args.mode == "bootstrap":
            logger.info("é€‰æ‹©bootstrapæ¨¡å¼")
            print(f"\næ‰§è¡Œé…ç½®ï¼š")
            print(f"æ¨¡å¼ï¼šbootstrap")
            print(f"è‹±æ–‡æºç ç›®å½•ï¼š{args.en_src}")
            print(f"ä¸­æ–‡æºç ç›®å½•ï¼š{args.zh_src}")
            print(f"æ¨¡ç»„IDï¼š{args.mod_id}")
            print(f"è¾“å‡ºæ–‡ä»¶ï¼š{args.out}")
            print(f"ä½¿ç”¨ç¼“å­˜ï¼š{args.use_cache}")
            print("===========================================")
            
            try:
                # å¯¼å…¥å¿…è¦çš„æ¨¡å—
                from src.common.tree_sitter_utils import extract_ast_mappings
                from src.common.yaml_utils import generate_translation_rules, save_yaml_mappings, load_yaml_mappings, RuleConflictDetector
                from datetime import datetime
                import re
                
                # ä»è‹±æ–‡æºç ç›®å½•æå–ASTæ˜ å°„
                print(f"[INFO] ä»è‹±æ–‡æºç ç›®å½•æå–æ˜ å°„è§„åˆ™ï¼š{args.en_src}")
                english_mappings = list(extract_ast_mappings(args.en_src, use_cache=args.use_cache))
                print(f"[OK] æˆåŠŸæå–è‹±æ–‡æ˜ å°„è§„åˆ™ {len(english_mappings)} æ¡")
                
                # ä»ä¸­æ–‡æºç ç›®å½•æå–ASTæ˜ å°„
                print(f"[INFO] ä»ä¸­æ–‡æºç ç›®å½•æå–æ˜ å°„è§„åˆ™ï¼š{args.zh_src}")
                chinese_mappings = list(extract_ast_mappings(args.zh_src, use_cache=args.use_cache))
                print(f"[OK] æˆåŠŸæå–ä¸­æ–‡æ˜ å°„è§„åˆ™ {len(chinese_mappings)} æ¡")
                
                # ä½¿ç”¨occurrence_keyè¿›è¡ŒåŒè¯­å¯¹é½
                print(f"[INFO] ä½¿ç”¨occurrence_keyè¿›è¡ŒåŒè¯­å¯¹é½...")
                
                # åˆ›å»ºè‹±æ–‡æ˜ å°„å­—å…¸ï¼Œä½¿ç”¨occurrence_keyä½œä¸ºé”®
                english_dict = {item['id']: item for item in english_mappings}
                chinese_dict = {item['id']: item for item in chinese_mappings}
                
                # æ‰¾åˆ°å…±åŒçš„occurrence_key
                common_keys = set(english_dict.keys()) & set(chinese_dict.keys())
                print(f"[INFO] æ‰¾åˆ° {len(common_keys)} ä¸ªå…±åŒçš„occurrence_key")
                
                # ç”Ÿæˆå¯¹é½çš„åŒè¯­æ˜ å°„
                aligned_en_mappings = []
                aligned_zh_mappings = []
                for key in common_keys:
                    aligned_en_mappings.append(english_dict[key])
                    aligned_zh_mappings.append(chinese_dict[key])
                
                # ç”Ÿæˆç¿»è¯‘è§„åˆ™
                print(f"[INFO] ç”Ÿæˆç¿»è¯‘è§„åˆ™...")
                success = generate_translation_rules(
                    aligned_en_mappings,
                    aligned_zh_mappings,
                    args.out,
                    args.mod_id
                )
                
                if success:
                    # æ£€æµ‹è§„åˆ™å†²çª
                    rules = load_yaml_mappings(args.out)
                    detector = RuleConflictDetector()
                    conflicts = detector.detect_all_conflicts(rules)
                    
                    conflict_info = {
                        "total_conflicts": conflicts['total_conflicts'],
                        "duplicate_ids": len(conflicts['duplicate_ids']),
                        "duplicate_originals": len(conflicts['duplicate_originals']),
                        "translation_conflicts": len(conflicts['translation_conflicts'])
                    }
                    
                    print(f"[OK] ç¿»è¯‘è§„åˆ™ç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶ï¼š{args.out}")
                    print(f"[OK] ç”Ÿæˆè§„åˆ™ {len(rules)} æ¡")
                    print(f"[INFO] å†²çªæ£€æµ‹ç»“æœï¼š")
                    print(f"  - æ€»å†²çªæ•°ï¼š{conflict_info['total_conflicts']}")
                    print(f"  - é‡å¤IDï¼š{conflict_info['duplicate_ids']}")
                    print(f"  - é‡å¤åŸå§‹å­—ç¬¦ä¸²ï¼š{conflict_info['duplicate_originals']}")
                    print(f"  - ç¿»è¯‘å†²çªï¼š{conflict_info['translation_conflicts']}")
                    
                    # å™ªå£°è¯†åˆ«å’ŒçŠ¶æ€å¤„ç†
                    print(f"[INFO] è¿›è¡Œå™ªå£°è¯†åˆ«å’ŒçŠ¶æ€å¤„ç†...")
                    updated_rules = []
                    noise_count = 0
                    need_review_count = 0
                    
                    for rule in rules:
                        updated_rule = rule.copy()
                        original = rule['original']
                        translated = rule['translated']
                        
                        # å™ªå£°è¯†åˆ«
                        is_noise = False
                        noise_reason = ""
                        noise_score = 0.0
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºèµ„æºè·¯å¾„/ID/çŸ­ä»¤ç‰Œ
                        if re.match(r'^[a-zA-Z0-9_]+$', original) and len(original) < 5:
                            is_noise = True
                            noise_reason = "çŸ­ä»¤ç‰Œ"
                            noise_score = 0.8
                        elif '/' in original or '\\' in original:
                            is_noise = True
                            noise_reason = "èµ„æºè·¯å¾„"
                            noise_score = 0.9
                        elif original.startswith('$') or original.startswith('%'):
                            is_noise = True
                            noise_reason = "ç‰¹æ®Šæ ‡è¯†ç¬¦"
                            noise_score = 0.7
                        
                        if is_noise:
                            updated_rule['status'] = "SKIP"
                            updated_rule['noise'] = {
                                "reason": noise_reason,
                                "score": noise_score
                            }
                            noise_count += 1
                        else:
                            # æ£€æŸ¥å ä½ç¬¦ä¸€è‡´æ€§
                            original_placeholders = re.findall(r'[%]\w+|\$\{.*?\}|\{.*?\}', original)
                            translated_placeholders = re.findall(r'[%]\w+|\$\{.*?\}|\{.*?\}', translated)
                            
                            if len(original_placeholders) != len(translated_placeholders):
                                updated_rule['status'] = "NEED_REVIEW"
                                updated_rule['review_reason'] = f"å ä½ç¬¦æ•°é‡ä¸ä¸€è‡´: åŸå§‹ {len(original_placeholders)} ä¸ªï¼Œç¿»è¯‘ {len(translated_placeholders)} ä¸ª"
                                need_review_count += 1
                            else:
                                updated_rule['status'] = "translated"
                        
                        updated_rules.append(updated_rule)
                    
                    # ä¿å­˜æ›´æ–°åçš„è§„åˆ™
                    save_yaml_mappings(updated_rules, args.out, version_control=True, mod_id=args.mod_id)
                    
                    print(f"[OK] å™ªå£°è¯†åˆ«å’ŒçŠ¶æ€å¤„ç†å®Œæˆ")
                    print(f"  - å™ªå£°è§„åˆ™æ•°ï¼š{noise_count}")
                    print(f"  - éœ€è¦å®¡æŸ¥çš„è§„åˆ™æ•°ï¼š{need_review_count}")
                    print(f"  - æ­£å¸¸ç¿»è¯‘è§„åˆ™æ•°ï¼š{len(updated_rules) - noise_count - need_review_count}")
                    
                    result = {
                        "status": "success",
                        "message": "bootstrapå‘½ä»¤æ‰§è¡ŒæˆåŠŸ",
                        "data": {
                            "output_path": args.out,
                            "english_mappings_count": len(english_mappings),
                            "chinese_mappings_count": len(chinese_mappings),
                            "common_keys_count": len(common_keys),
                            "generated_rules_count": len(updated_rules),
                            "noise_count": noise_count,
                            "need_review_count": need_review_count,
                            "conflicts": conflict_info
                        }
                    }
                else:
                    result = {
                        "status": "error",
                        "message": "ç”Ÿæˆç¿»è¯‘è§„åˆ™å¤±è´¥"
                    }
                
            except SystemExit:
                # å¤„ç†argparseçš„é€€å‡º
                result = {"status": "error", "message": "å‚æ•°è§£æå¤±è´¥"}
            except Exception as e:
                logger.exception(f"bootstrapå‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                print(f"[ERROR] bootstrapå‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                result = {"status": "error", "message": str(e)}
        elif args.mode == "rules":
            logger.info("é€‰æ‹©rulesæ¨¡å¼")
            print(f"\næ‰§è¡Œé…ç½®ï¼š")
            print(f"æ¨¡å¼ï¼šrules")
            print(f"å­å‘½ä»¤ï¼š{args.subcommand}")
            print(f"å‚æ•°ï¼š{' '.join(args.args)}")
            print("===========================================")
            
            try:
                from src.common.rules_store import RulesStore
                
                # è§£æé€šç”¨å‚æ•°
                common_parser = argparse.ArgumentParser(add_help=False)
                common_parser.add_argument("--rules-file", required=True, help="è§„åˆ™æ–‡ä»¶è·¯å¾„")
                
                # å¤„ç†ä¸åŒçš„å­å‘½ä»¤
                if args.subcommand == "list":
                    # è§£ælistå­å‘½ä»¤å‚æ•°
                    list_parser = argparse.ArgumentParser(prog="rules list", parents=[common_parser])
                    list_parser.add_argument("--status", help="æŒ‰çŠ¶æ€è¿‡æ»¤è§„åˆ™")
                    list_parser.add_argument("--file", help="æŒ‰æ–‡ä»¶è¿‡æ»¤è§„åˆ™")
                    list_args = list_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(list_args.rules_file)
                    if rules_store.load_rules():
                        # è¿‡æ»¤è§„åˆ™
                        filtered_rules = rules_store.rules
                        if list_args.status:
                            filtered_rules = rules_store.get_rules_by_status(list_args.status)
                        if list_args.file:
                            filtered_rules = rules_store.get_rules_by_file(list_args.file)
                        
                        # è¾“å‡ºè§„åˆ™åˆ—è¡¨
                        print(f"[INFO] è§„åˆ™åˆ—è¡¨ ({len(filtered_rules)} æ¡):")
                        for rule in filtered_rules:
                            print(f"ID: {rule['id']}")
                            print(f"  Original: {rule['original']}")
                            print(f"  Translated: {rule.get('translated', '')}")
                            print(f"  Status: {rule.get('status', 'untranslated')}")
                            print(f"  File: {rule.get('meta', {}).get('file', '')}")
                            print()
                        
                        result = {
                            "status": "success",
                            "message": f"æˆåŠŸåˆ—å‡º {len(filtered_rules)} æ¡è§„åˆ™",
                            "data": {
                                "total_rules": len(rules_store.rules),
                                "filtered_rules": len(filtered_rules)
                            }
                        }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "show":
                    # è§£æshowå­å‘½ä»¤å‚æ•°
                    show_parser = argparse.ArgumentParser(prog="rules show", parents=[common_parser])
                    show_parser.add_argument("--rule-id", required=True, help="è§„åˆ™ID")
                    show_args = show_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(show_args.rules_file)
                    if rules_store.load_rules():
                        # è·å–è§„åˆ™
                        rule = rules_store.get_rule(show_args.rule_id)
                        if rule:
                            print(f"[INFO] è§„åˆ™è¯¦æƒ…:")
                            print(f"ID: {rule['id']}")
                            print(f"Original: {rule['original']}")
                            print(f"Translated: {rule.get('translated', '')}")
                            print(f"Status: {rule.get('status', 'untranslated')}")
                            print(f"File: {rule.get('meta', {}).get('file', '')}")
                            print(f"Line: {rule.get('meta', {}).get('line', '')}")
                            print(f"Context: {rule.get('context', {})}")
                            print(f"Placeholders: {rule.get('placeholders', [])}")
                            print(f"Created At: {rule.get('created_at', '')}")
                            print(f"Updated At: {rule.get('updated_at', '')}")
                            print(f"Noise: {rule.get('noise', {})}")
                            print(f"Review Reason: {rule.get('review_reason', '')}")
                            
                            result = {
                                "status": "success",
                                "message": "æˆåŠŸæ˜¾ç¤ºè§„åˆ™è¯¦æƒ…",
                                "data": rule
                            }
                        else:
                            result = {
                                "status": "error",
                                "message": f"æœªæ‰¾åˆ°è§„åˆ™: {show_args.rule_id}"
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "set":
                    # è§£æsetå­å‘½ä»¤å‚æ•°
                    set_parser = argparse.ArgumentParser(prog="rules set", parents=[common_parser])
                    set_parser.add_argument("--rule-id", required=True, help="è§„åˆ™ID")
                    set_parser.add_argument("--translated", help="ç¿»è¯‘å†…å®¹")
                    set_parser.add_argument("--status", help="è§„åˆ™çŠ¶æ€")
                    set_args = set_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(set_args.rules_file)
                    if rules_store.load_rules():
                        # å‡†å¤‡æ›´æ–°å†…å®¹
                        updates = {}
                        if set_args.translated is not None:
                            updates["translated"] = set_args.translated
                        if set_args.status:
                            updates["status"] = set_args.status
                        
                        if updates:
                            # æ›´æ–°è§„åˆ™
                            if rules_store.update_rule(set_args.rule_id, updates):
                                # ä¿å­˜æ›´æ–°åçš„è§„åˆ™
                                if rules_store.save_rules():
                                    result = {
                                        "status": "success",
                                        "message": f"æˆåŠŸæ›´æ–°è§„åˆ™: {set_args.rule_id}"
                                    }
                                else:
                                    result = {
                                        "status": "error",
                                        "message": "ä¿å­˜è§„åˆ™æ–‡ä»¶å¤±è´¥"
                                    }
                            else:
                                result = {
                                    "status": "error",
                                    "message": f"æœªæ‰¾åˆ°è§„åˆ™: {set_args.rule_id}"
                                }
                        else:
                            result = {
                                "status": "error",
                                "message": "æ²¡æœ‰æä¾›æ›´æ–°å†…å®¹"
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "delete":
                    # è§£ædeleteå­å‘½ä»¤å‚æ•°
                    delete_parser = argparse.ArgumentParser(prog="rules delete", parents=[common_parser])
                    delete_parser.add_argument("--rule-id", required=True, help="è§„åˆ™ID")
                    delete_args = delete_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(delete_args.rules_file)
                    if rules_store.load_rules():
                        # åˆ é™¤è§„åˆ™
                        if rules_store.delete_rule(delete_args.rule_id):
                            # ä¿å­˜æ›´æ–°åçš„è§„åˆ™
                            if rules_store.save_rules():
                                result = {
                                    "status": "success",
                                    "message": f"æˆåŠŸåˆ é™¤è§„åˆ™: {delete_args.rule_id}"
                                }
                            else:
                                result = {
                                    "status": "error",
                                    "message": "ä¿å­˜è§„åˆ™æ–‡ä»¶å¤±è´¥"
                                }
                        else:
                            result = {
                                "status": "error",
                                "message": f"æœªæ‰¾åˆ°è§„åˆ™: {delete_args.rule_id}"
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "validate":
                    # è§£ævalidateå­å‘½ä»¤å‚æ•°
                    validate_parser = argparse.ArgumentParser(prog="rules validate", parents=[common_parser])
                    validate_args = validate_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(validate_args.rules_file)
                    if rules_store.load_rules():
                        # éªŒè¯è§„åˆ™
                        errors = rules_store.validate_rules()
                        
                        if errors:
                            print(f"[ERROR] å‘ç° {len(errors)} ä¸ªé”™è¯¯:")
                            for error in errors:
                                print(f"  - {error}")
                            
                            result = {
                                "status": "error",
                                "message": f"è§„åˆ™éªŒè¯å¤±è´¥ï¼Œå‘ç° {len(errors)} ä¸ªé”™è¯¯",
                                "data": {
                                    "errors": errors
                                }
                            }
                        else:
                            print(f"[OK] è§„åˆ™éªŒè¯é€šè¿‡ï¼Œæœªå‘ç°é”™è¯¯")
                            
                            result = {
                                "status": "success",
                                "message": "è§„åˆ™éªŒè¯é€šè¿‡",
                                "data": {
                                    "total_rules": len(rules_store.rules)
                                }
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "import":
                    # è§£æimportå­å‘½ä»¤å‚æ•°
                    import_parser = argparse.ArgumentParser(prog="rules import", parents=[common_parser])
                    import_parser.add_argument("--source-file", required=True, help="æºè§„åˆ™æ–‡ä»¶è·¯å¾„")
                    import_parser.add_argument("--merge", action="store_true", help="æ˜¯å¦åˆå¹¶åˆ°ç°æœ‰è§„åˆ™ï¼Œå¦åˆ™æ›¿æ¢")
                    import_args = import_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(import_args.rules_file)
                    if rules_store.load_rules():
                        # å¯¼å…¥è§„åˆ™
                        import_result = rules_store.import_rules(import_args.source_file, import_args.merge)
                        
                        # ä¿å­˜æ›´æ–°åçš„è§„åˆ™
                        if rules_store.save_rules():
                            result = {
                                "status": "success",
                                "message": import_result["message"],
                                "data": import_result
                            }
                        else:
                            result = {
                                "status": "error",
                                "message": "ä¿å­˜è§„åˆ™æ–‡ä»¶å¤±è´¥"
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                elif args.subcommand == "export":
                    # è§£æexportå­å‘½ä»¤å‚æ•°
                    export_parser = argparse.ArgumentParser(prog="rules export", parents=[common_parser])
                    export_parser.add_argument("--out", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
                    export_parser.add_argument("--format", default="rich", choices=["rich", "simple"], help="å¯¼å‡ºæ ¼å¼")
                    export_args = export_parser.parse_args(args.args)
                    
                    # åˆ›å»ºRulesStoreå®ä¾‹
                    rules_store = RulesStore(export_args.rules_file)
                    if rules_store.load_rules():
                        # å¯¼å‡ºè§„åˆ™
                        if rules_store.export_rules(export_args.out, export_args.format):
                            result = {
                                "status": "success",
                                "message": f"æˆåŠŸå¯¼å‡ºè§„åˆ™åˆ° {export_args.out}",
                                "data": {
                                    "exported_rules": len(rules_store.rules),
                                    "format": export_args.format
                                }
                            }
                        else:
                            result = {
                                "status": "error",
                                "message": "å¯¼å‡ºè§„åˆ™å¤±è´¥"
                            }
                    else:
                        result = {
                            "status": "error",
                            "message": "åŠ è½½è§„åˆ™æ–‡ä»¶å¤±è´¥"
                        }
                
                else:
                    result = {
                        "status": "error",
                        "message": f"æœªçŸ¥çš„å­å‘½ä»¤: {args.subcommand}"
                    }
                
            except SystemExit:
                # å¤„ç†argparseçš„é€€å‡º
                result = {"status": "error", "message": "å‚æ•°è§£æå¤±è´¥"}
            except Exception as e:
                logger.exception(f"ruleså‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                print(f"[ERROR] ruleså‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                result = {"status": "error", "message": str(e)}
        else:
            # æ²¡æœ‰æŒ‡å®šæ¨¡å¼ï¼Œä½¿ç”¨äº¤äº’å¼èœå•
            logger.info("æœªæŒ‡å®šæ¨¡å¼ï¼Œæ˜¾ç¤ºä¸»èœå•")
            mode = select_main_mode()
            logger.info(f"ç”¨æˆ·é€‰æ‹©ä¸»æ¨¡å¼ï¼š{mode}")

            if mode == "1":
                # Extractæ¨¡å¼
                sub_flow = select_extract_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Extractå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtract")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_extract_sub_flow(sub_flow, None)
            elif mode == "2":
                # Extendæ¨¡å¼
                sub_flow = select_extend_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Extendå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šExtend")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_extend_sub_flow(sub_flow, None)
            elif mode == "3":
                # Decompileæ¨¡å¼
                sub_flow = select_decompile_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©Decompileå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šDecompile")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("==========================================")
                result = run_decompile_sub_flow(sub_flow, None)
            elif mode == "4":
                # æ–‡ä»¶ç®¡ç†æ¨¡å¼
                sub_flow = select_file_management_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©æ–‡ä»¶ç®¡ç†å­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šæ–‡ä»¶ç®¡ç†")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("===========================================")
                result = run_file_management_sub_flow(sub_flow, None)
            elif mode == "5":
                # æ˜ å°„è§„åˆ™ç®¡ç†
                logger.info("é€‰æ‹©æ˜ å°„è§„åˆ™ç®¡ç†æ¨¡å¼")
                sub_flow = select_localization_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©æ˜ å°„è§„åˆ™ç®¡ç†å­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šæ˜ å°„è§„åˆ™ç®¡ç†")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("===========================================")
                result = run_localization_sub_flow(sub_flow, None)
            elif mode == "6":
                # å®Œæ•´å·¥ä½œæµ
                logger.info("é€‰æ‹©å®Œæ•´å·¥ä½œæµæ¨¡å¼")
                sub_flow = select_workflow_sub_flow()
                logger.info(f"ç”¨æˆ·é€‰æ‹©å®Œæ•´å·¥ä½œæµå­æµç¨‹ï¼š{sub_flow}")
                print(f"\næ‰§è¡Œé…ç½®ï¼š")
                print(f"æ¨¡å¼ï¼šå®Œæ•´å·¥ä½œæµ")
                print(f"æµç¨‹ï¼š{sub_flow}")
                print("===========================================")
                result = run_workflow_sub_flow(sub_flow, None)
        
        # å¤„ç†æ‰§è¡Œç»“æœ
        if result and isinstance(result, dict):
            logger.info(f"æ¨¡å¼æ‰§è¡Œå®Œæˆï¼š{result['status']}")
            if result.get("data", {}).get("output_path"):
                # æ ¹æ®æ¨¡å¼åˆ¤æ–­è¯­è¨€ç±»å‹
                if args.mode == "extract" or mode == "1":
                    # Extractæ¨¡å¼
                    language = "English" if "è‹±æ–‡" in result.get("sub_flow", "") else "Chinese"
                    show_output_guide(result["data"]["output_path"], "Extract", language)
                elif args.mode == "extend" or mode == "2":
                    # Extendæ¨¡å¼
                    language = "English" if "ä¸­æ–‡â†’è‹±æ–‡" in result.get("sub_flow", "") else "Chinese"
                    show_output_guide(result["data"]["output_path"], "Extend", language)
        
        logger.info("å·¥å…·æ‰§è¡Œå®Œæˆï¼Œé€€å‡º")
    except Exception as e:
        logger.exception(f"å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        print(f"[ERROR] å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
